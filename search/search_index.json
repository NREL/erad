{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"ERAD Installation Instruction We recommend using Anaconda or Miniconda to create the environment for windows user. Use the commands below to create environment and install the ERAD tool. Windows 10 + Mac OS & linux conda create -n erad python==3.8 conda activate erad conda install shapely git clone https://github.nrel.gov/ERAD/erad.git cd erad pip install -e. conda create -n erad python==3.8 conda activate erad git clone https://github.nrel.gov/ERAD/erad.git cd erad pip install -e.","title":"Welcome"},{"location":"#erad","text":"","title":"ERAD"},{"location":"#installation-instruction","text":"We recommend using Anaconda or Miniconda to create the environment for windows user. Use the commands below to create environment and install the ERAD tool. Windows 10 + Mac OS & linux conda create -n erad python==3.8 conda activate erad conda install shapely git clone https://github.nrel.gov/ERAD/erad.git cd erad pip install -e. conda create -n erad python==3.8 conda activate erad git clone https://github.nrel.gov/ERAD/erad.git cd erad pip install -e.","title":"Installation Instruction"},{"location":"db_neo4j/","text":"Module contains class and utility functions to manage interactions with Neo4J database. Neo4J Class for managing interaction with Neo4J database. Attributes: Name Type Description neo4j_url str URL for connecting to Neo4j neo4j_username str Username for Neo4j database neo4j_password str Password for Neo4j database use_env bool True if above info are to be collected from env file. driver GraphDatabase . driver Neo4J driver instance Source code in erad\\db\\neo4j_.py 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 class Neo4J : \"\"\"Class for managing interaction with Neo4J database. Attributes: neo4j_url (str): URL for connecting to Neo4j neo4j_username (str): Username for Neo4j database neo4j_password (str): Password for Neo4j database use_env (bool): True if above info are to be collected from env file. driver (GraphDatabase.driver): Neo4J driver instance \"\"\" def __init__ ( self , neo4j_url : Union [ str , None ] = None , neo4j_username : Union [ str , None ] = None , neo4j_password : Union [ str , None ] = None , ) -> None : \"\"\"Constructor for Neo4J class. Args: neo4j_url (str): URL for connecting to Neo4j neo4j_username (str): Username for Neo4j database neo4j_password (str): Password for Neo4j database \"\"\" self . neo4j_url = NEO4J_URL if NEO4J_URL else neo4j_url self . neo4j_username = ( NEO4J_USERNAME if NEO4J_USERNAME else neo4j_username ) self . neo4j_password = ( NEO4J_PASSWORD if NEO4J_PASSWORD else neo4j_password ) connection = Neo4jConnectionModel ( neo4j_url = self . neo4j_url , neo4j_username = self . neo4j_username , neo4j_password = self . neo4j_password , ) self . driver = GraphDatabase . driver ( connection . neo4j_url , auth = basic_auth ( connection . neo4j_username , connection . neo4j_password ), ) logger . debug ( f \"Connected to { connection . neo4j_url } database successfully\" ) @staticmethod def rename_labels ( label ): \"\"\"Method to replace the invalid character.\"\"\" invalid_chars = [ \"-\" , \":\" , \"(\" , \")\" , \".\" ] for invalid_char in invalid_chars : if invalid_char in label : label = label . replace ( invalid_char , \"__\" ) return label # def add_node( # self, # labels: Union[List, None] = None, # properties: Union[Dict, None] = None, # ) -> None: # \"\"\"Method to add node to the Neo4j database. # Args: # labels (Union[List, None]): List of labels to be used for node # properties (Union[Dict, None]): Properties to be used for the node # \"\"\" # if labels is None: # labels = [] # if properties is None: # properties = {} # labels = \":\".join([self.rename_labels(label) for label in labels]) # cypher_query = \"CREATE (:\" + labels + \" $properties)\" # with self.driver.session() as session: # session.write_transaction( # lambda tx: tx.run(cypher_query, properties=properties) # ) # def add_relationship( # self, # from_node_label: str, # to_node_label: str, # from_node: str, # to_node: str, # relationship_label: str, # relationship_properties: Union[Dict, None] = None, # ) -> None: # \"\"\"Method to create relationship in graph database. # Args: # from_node_label (str): Node label for from node # to_node_label (str): Node label for to node # from_node (str): From node name # to_node (str): To node name # relationship_label (str): Relationship label name # relationship_properties (Union[Dict, None]): Properties to be used # for relationship # \"\"\" # if relationship_properties is None: # relationship_properties = {} # cypher_query = ( # f\"MATCH (a:{from_node_label}),(b:{to_node_label}) WHERE a.name = '{from_node}'\" # + f\" AND b.name = '{to_node}' CREATE (a)-[:\" # + self.rename_labels(relationship_label) # + \" $properties]->(b)\" # ) # with self.driver.session() as session: # session.write_transaction( # lambda tx: tx.run( # cypher_query, properties=relationship_properties # ) # ) # def read_query(self, cypher_query: str) -> List: # \"\"\"Executes a Cypher read query.\"\"\" # with self.driver.session() as session: # result = session.read_transaction( # lambda tx: tx.run(cypher_query).data() # ) # return result def close_driver ( self ): \"\"\"Method to close the driver.\"\"\" self . driver . close () __init__ ( neo4j_url = None , neo4j_username = None , neo4j_password = None ) Constructor for Neo4J class. Parameters: Name Type Description Default neo4j_url str URL for connecting to Neo4j None neo4j_username str Username for Neo4j database None neo4j_password str Password for Neo4j database None Source code in erad\\db\\neo4j_.py 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 def __init__ ( self , neo4j_url : Union [ str , None ] = None , neo4j_username : Union [ str , None ] = None , neo4j_password : Union [ str , None ] = None , ) -> None : \"\"\"Constructor for Neo4J class. Args: neo4j_url (str): URL for connecting to Neo4j neo4j_username (str): Username for Neo4j database neo4j_password (str): Password for Neo4j database \"\"\" self . neo4j_url = NEO4J_URL if NEO4J_URL else neo4j_url self . neo4j_username = ( NEO4J_USERNAME if NEO4J_USERNAME else neo4j_username ) self . neo4j_password = ( NEO4J_PASSWORD if NEO4J_PASSWORD else neo4j_password ) connection = Neo4jConnectionModel ( neo4j_url = self . neo4j_url , neo4j_username = self . neo4j_username , neo4j_password = self . neo4j_password , ) self . driver = GraphDatabase . driver ( connection . neo4j_url , auth = basic_auth ( connection . neo4j_username , connection . neo4j_password ), ) logger . debug ( f \"Connected to { connection . neo4j_url } database successfully\" ) close_driver () Method to close the driver. Source code in erad\\db\\neo4j_.py 160 161 162 def close_driver ( self ): \"\"\"Method to close the driver.\"\"\" self . driver . close () rename_labels ( label ) staticmethod Method to replace the invalid character. Source code in erad\\db\\neo4j_.py 78 79 80 81 82 83 84 85 @staticmethod def rename_labels ( label ): \"\"\"Method to replace the invalid character.\"\"\" invalid_chars = [ \"-\" , \":\" , \"(\" , \")\" , \".\" ] for invalid_char in invalid_chars : if invalid_char in label : label = label . replace ( invalid_char , \"__\" ) return label","title":"db.neo4j"},{"location":"db_neo4j/#erad.db.neo4j_.Neo4J","text":"Class for managing interaction with Neo4J database. Attributes: Name Type Description neo4j_url str URL for connecting to Neo4j neo4j_username str Username for Neo4j database neo4j_password str Password for Neo4j database use_env bool True if above info are to be collected from env file. driver GraphDatabase . driver Neo4J driver instance Source code in erad\\db\\neo4j_.py 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 class Neo4J : \"\"\"Class for managing interaction with Neo4J database. Attributes: neo4j_url (str): URL for connecting to Neo4j neo4j_username (str): Username for Neo4j database neo4j_password (str): Password for Neo4j database use_env (bool): True if above info are to be collected from env file. driver (GraphDatabase.driver): Neo4J driver instance \"\"\" def __init__ ( self , neo4j_url : Union [ str , None ] = None , neo4j_username : Union [ str , None ] = None , neo4j_password : Union [ str , None ] = None , ) -> None : \"\"\"Constructor for Neo4J class. Args: neo4j_url (str): URL for connecting to Neo4j neo4j_username (str): Username for Neo4j database neo4j_password (str): Password for Neo4j database \"\"\" self . neo4j_url = NEO4J_URL if NEO4J_URL else neo4j_url self . neo4j_username = ( NEO4J_USERNAME if NEO4J_USERNAME else neo4j_username ) self . neo4j_password = ( NEO4J_PASSWORD if NEO4J_PASSWORD else neo4j_password ) connection = Neo4jConnectionModel ( neo4j_url = self . neo4j_url , neo4j_username = self . neo4j_username , neo4j_password = self . neo4j_password , ) self . driver = GraphDatabase . driver ( connection . neo4j_url , auth = basic_auth ( connection . neo4j_username , connection . neo4j_password ), ) logger . debug ( f \"Connected to { connection . neo4j_url } database successfully\" ) @staticmethod def rename_labels ( label ): \"\"\"Method to replace the invalid character.\"\"\" invalid_chars = [ \"-\" , \":\" , \"(\" , \")\" , \".\" ] for invalid_char in invalid_chars : if invalid_char in label : label = label . replace ( invalid_char , \"__\" ) return label # def add_node( # self, # labels: Union[List, None] = None, # properties: Union[Dict, None] = None, # ) -> None: # \"\"\"Method to add node to the Neo4j database. # Args: # labels (Union[List, None]): List of labels to be used for node # properties (Union[Dict, None]): Properties to be used for the node # \"\"\" # if labels is None: # labels = [] # if properties is None: # properties = {} # labels = \":\".join([self.rename_labels(label) for label in labels]) # cypher_query = \"CREATE (:\" + labels + \" $properties)\" # with self.driver.session() as session: # session.write_transaction( # lambda tx: tx.run(cypher_query, properties=properties) # ) # def add_relationship( # self, # from_node_label: str, # to_node_label: str, # from_node: str, # to_node: str, # relationship_label: str, # relationship_properties: Union[Dict, None] = None, # ) -> None: # \"\"\"Method to create relationship in graph database. # Args: # from_node_label (str): Node label for from node # to_node_label (str): Node label for to node # from_node (str): From node name # to_node (str): To node name # relationship_label (str): Relationship label name # relationship_properties (Union[Dict, None]): Properties to be used # for relationship # \"\"\" # if relationship_properties is None: # relationship_properties = {} # cypher_query = ( # f\"MATCH (a:{from_node_label}),(b:{to_node_label}) WHERE a.name = '{from_node}'\" # + f\" AND b.name = '{to_node}' CREATE (a)-[:\" # + self.rename_labels(relationship_label) # + \" $properties]->(b)\" # ) # with self.driver.session() as session: # session.write_transaction( # lambda tx: tx.run( # cypher_query, properties=relationship_properties # ) # ) # def read_query(self, cypher_query: str) -> List: # \"\"\"Executes a Cypher read query.\"\"\" # with self.driver.session() as session: # result = session.read_transaction( # lambda tx: tx.run(cypher_query).data() # ) # return result def close_driver ( self ): \"\"\"Method to close the driver.\"\"\" self . driver . close ()","title":"Neo4J"},{"location":"db_neo4j/#erad.db.neo4j_.Neo4J.__init__","text":"Constructor for Neo4J class. Parameters: Name Type Description Default neo4j_url str URL for connecting to Neo4j None neo4j_username str Username for Neo4j database None neo4j_password str Password for Neo4j database None Source code in erad\\db\\neo4j_.py 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 def __init__ ( self , neo4j_url : Union [ str , None ] = None , neo4j_username : Union [ str , None ] = None , neo4j_password : Union [ str , None ] = None , ) -> None : \"\"\"Constructor for Neo4J class. Args: neo4j_url (str): URL for connecting to Neo4j neo4j_username (str): Username for Neo4j database neo4j_password (str): Password for Neo4j database \"\"\" self . neo4j_url = NEO4J_URL if NEO4J_URL else neo4j_url self . neo4j_username = ( NEO4J_USERNAME if NEO4J_USERNAME else neo4j_username ) self . neo4j_password = ( NEO4J_PASSWORD if NEO4J_PASSWORD else neo4j_password ) connection = Neo4jConnectionModel ( neo4j_url = self . neo4j_url , neo4j_username = self . neo4j_username , neo4j_password = self . neo4j_password , ) self . driver = GraphDatabase . driver ( connection . neo4j_url , auth = basic_auth ( connection . neo4j_username , connection . neo4j_password ), ) logger . debug ( f \"Connected to { connection . neo4j_url } database successfully\" )","title":"__init__()"},{"location":"db_neo4j/#erad.db.neo4j_.Neo4J.close_driver","text":"Method to close the driver. Source code in erad\\db\\neo4j_.py 160 161 162 def close_driver ( self ): \"\"\"Method to close the driver.\"\"\" self . driver . close ()","title":"close_driver()"},{"location":"db_neo4j/#erad.db.neo4j_.Neo4J.rename_labels","text":"Method to replace the invalid character. Source code in erad\\db\\neo4j_.py 78 79 80 81 82 83 84 85 @staticmethod def rename_labels ( label ): \"\"\"Method to replace the invalid character.\"\"\" invalid_chars = [ \"-\" , \":\" , \"(\" , \")\" , \".\" ] for invalid_char in invalid_chars : if invalid_char in label : label = label . replace ( invalid_char , \"__\" ) return label","title":"rename_labels()"},{"location":"developers-guide/","text":"","title":"Guide to Developers"},{"location":"exceptions/","text":"Module for managing exceptions raised by ERAD package. DatabaseMissingInfo Bases: ERADBaseException Exception raised because information required to connect to database is missing. Source code in erad\\exceptions.py 37 38 class DatabaseMissingInfo ( ERADBaseException ): \"\"\"Exception raised because information required to connect to database is missing.\"\"\" DittoException Bases: ERADBaseException Exceptions raised because application ran into an issus using Ditto. Source code in erad\\exceptions.py 67 68 class DittoException ( ERADBaseException ): \"\"\"Exceptions raised because application ran into an issus using Ditto.\"\"\" ERADBaseException Bases: Exception All exception should derive from this. Source code in erad\\exceptions.py 7 8 class ERADBaseException ( Exception ): \"\"\"All exception should derive from this.\"\"\" EmptyEnvironmentVariable Bases: ERADBaseException Exception raised because environment variable required is empty. Source code in erad\\exceptions.py 33 34 class EmptyEnvironmentVariable ( ERADBaseException ): \"\"\"Exception raised because environment variable required is empty.\"\"\" EmptyScenarioPolygon Bases: ERADBaseException Exceptions raised because no polygons are found. Source code in erad\\exceptions.py 54 55 class EmptyScenarioPolygon ( ERADBaseException ): \"\"\"Exceptions raised because no polygons are found.\"\"\" FeatureNotImplementedError Bases: ERADBaseException Exception raised because specific feature requested has not been implemented. Source code in erad\\exceptions.py 11 12 class FeatureNotImplementedError ( ERADBaseException ): \"\"\"Exception raised because specific feature requested has not been implemented.\"\"\" InvalidFileTypePassed Bases: ERADBaseException Exceptions raised because invalid file type is passed. Source code in erad\\exceptions.py 41 42 43 44 45 46 47 class InvalidFileTypePassed ( ERADBaseException ): \"\"\"Exceptions raised because invalid file type is passed.\"\"\" def __init__ ( self , path , valid_type ): self . message = f \"Invalid file type of { Path ( path ) . suffix } is passed! Please pass valid file type of { valid_type } \" super () . __init__ ( self . message ) MultiStatePlaneError Bases: ERADBaseException Exceptions raised because the corrdinates are in more than one state plane coordinates. Source code in erad\\exceptions.py 62 63 64 class MultiStatePlaneError ( ERADBaseException ): \"\"\"Exceptions raised because the corrdinates are in more than one state plane coordinates.\"\"\" NotAFileError Bases: ERADBaseException Exception raised because file is expected but folder path is provided. Source code in erad\\exceptions.py 25 26 27 28 29 30 class NotAFileError ( ERADBaseException ): \"\"\"Exception raised because file is expected but folder path is provided.\"\"\" def __init__ ( self , path ): self . message = f \"Expected file path { path } is not a file!\" super () . __init__ ( self . message ) OpenDSSCommandError Bases: ERADBaseException Exceptions raised because opendss command execution ran into an error. Source code in erad\\exceptions.py 58 59 class OpenDSSCommandError ( ERADBaseException ): \"\"\"Exceptions raised because opendss command execution ran into an error.\"\"\" PathDoesNotExist Bases: ERADBaseException Exception raised bacause expected file/folder path does not exist. Source code in erad\\exceptions.py 15 16 17 18 19 20 21 22 class PathDoesNotExist ( ERADBaseException ): \"\"\"Exception raised bacause expected file/folder path does not exist.\"\"\" def __init__ ( self , path ): self . message = ( f \"Expected path { path } does not exist. please check you file path!\" ) super () . __init__ ( self . message ) SMARTDSInvalidInput Bases: ERADBaseException Exceptions raised because invalid input is provided for SMART DS data download. Source code in erad\\exceptions.py 50 51 class SMARTDSInvalidInput ( ERADBaseException ): \"\"\"Exceptions raised because invalid input is provided for SMART DS data download.\"\"\"","title":"exceptions"},{"location":"exceptions/#erad.exceptions.DatabaseMissingInfo","text":"Bases: ERADBaseException Exception raised because information required to connect to database is missing. Source code in erad\\exceptions.py 37 38 class DatabaseMissingInfo ( ERADBaseException ): \"\"\"Exception raised because information required to connect to database is missing.\"\"\"","title":"DatabaseMissingInfo"},{"location":"exceptions/#erad.exceptions.DittoException","text":"Bases: ERADBaseException Exceptions raised because application ran into an issus using Ditto. Source code in erad\\exceptions.py 67 68 class DittoException ( ERADBaseException ): \"\"\"Exceptions raised because application ran into an issus using Ditto.\"\"\"","title":"DittoException"},{"location":"exceptions/#erad.exceptions.ERADBaseException","text":"Bases: Exception All exception should derive from this. Source code in erad\\exceptions.py 7 8 class ERADBaseException ( Exception ): \"\"\"All exception should derive from this.\"\"\"","title":"ERADBaseException"},{"location":"exceptions/#erad.exceptions.EmptyEnvironmentVariable","text":"Bases: ERADBaseException Exception raised because environment variable required is empty. Source code in erad\\exceptions.py 33 34 class EmptyEnvironmentVariable ( ERADBaseException ): \"\"\"Exception raised because environment variable required is empty.\"\"\"","title":"EmptyEnvironmentVariable"},{"location":"exceptions/#erad.exceptions.EmptyScenarioPolygon","text":"Bases: ERADBaseException Exceptions raised because no polygons are found. Source code in erad\\exceptions.py 54 55 class EmptyScenarioPolygon ( ERADBaseException ): \"\"\"Exceptions raised because no polygons are found.\"\"\"","title":"EmptyScenarioPolygon"},{"location":"exceptions/#erad.exceptions.FeatureNotImplementedError","text":"Bases: ERADBaseException Exception raised because specific feature requested has not been implemented. Source code in erad\\exceptions.py 11 12 class FeatureNotImplementedError ( ERADBaseException ): \"\"\"Exception raised because specific feature requested has not been implemented.\"\"\"","title":"FeatureNotImplementedError"},{"location":"exceptions/#erad.exceptions.InvalidFileTypePassed","text":"Bases: ERADBaseException Exceptions raised because invalid file type is passed. Source code in erad\\exceptions.py 41 42 43 44 45 46 47 class InvalidFileTypePassed ( ERADBaseException ): \"\"\"Exceptions raised because invalid file type is passed.\"\"\" def __init__ ( self , path , valid_type ): self . message = f \"Invalid file type of { Path ( path ) . suffix } is passed! Please pass valid file type of { valid_type } \" super () . __init__ ( self . message )","title":"InvalidFileTypePassed"},{"location":"exceptions/#erad.exceptions.MultiStatePlaneError","text":"Bases: ERADBaseException Exceptions raised because the corrdinates are in more than one state plane coordinates. Source code in erad\\exceptions.py 62 63 64 class MultiStatePlaneError ( ERADBaseException ): \"\"\"Exceptions raised because the corrdinates are in more than one state plane coordinates.\"\"\"","title":"MultiStatePlaneError"},{"location":"exceptions/#erad.exceptions.NotAFileError","text":"Bases: ERADBaseException Exception raised because file is expected but folder path is provided. Source code in erad\\exceptions.py 25 26 27 28 29 30 class NotAFileError ( ERADBaseException ): \"\"\"Exception raised because file is expected but folder path is provided.\"\"\" def __init__ ( self , path ): self . message = f \"Expected file path { path } is not a file!\" super () . __init__ ( self . message )","title":"NotAFileError"},{"location":"exceptions/#erad.exceptions.OpenDSSCommandError","text":"Bases: ERADBaseException Exceptions raised because opendss command execution ran into an error. Source code in erad\\exceptions.py 58 59 class OpenDSSCommandError ( ERADBaseException ): \"\"\"Exceptions raised because opendss command execution ran into an error.\"\"\"","title":"OpenDSSCommandError"},{"location":"exceptions/#erad.exceptions.PathDoesNotExist","text":"Bases: ERADBaseException Exception raised bacause expected file/folder path does not exist. Source code in erad\\exceptions.py 15 16 17 18 19 20 21 22 class PathDoesNotExist ( ERADBaseException ): \"\"\"Exception raised bacause expected file/folder path does not exist.\"\"\" def __init__ ( self , path ): self . message = ( f \"Expected path { path } does not exist. please check you file path!\" ) super () . __init__ ( self . message )","title":"PathDoesNotExist"},{"location":"exceptions/#erad.exceptions.SMARTDSInvalidInput","text":"Bases: ERADBaseException Exceptions raised because invalid input is provided for SMART DS data download. Source code in erad\\exceptions.py 50 51 class SMARTDSInvalidInput ( ERADBaseException ): \"\"\"Exceptions raised because invalid input is provided for SMART DS data download.\"\"\"","title":"SMARTDSInvalidInput"},{"location":"how-to-guides/","text":"","title":"How to Guides"},{"location":"tutorial_resilience_metrics/","text":"","title":"Compute resilience metrics"},{"location":"utils_ditto_utils/","text":"Utility functions for dealing with SMART DS dataset. Examples: >>> from erad import ditto_utils >>> ditto_utils . download_smartds_data ( 'P4R' , '.' ) create_networkx_from_ditto ( output_path , file_name , ** kwargs ) Creates networkx graph from OpenDSS model using Ditto. Parameters: Name Type Description Default output_path str Path to store the networkx data in json file format required file_name str JSON file name used to export the network required kwargs dict Keyword arguments accepted by Ditto required Source code in erad\\utils\\ditto_utils.py 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 def create_networkx_from_ditto ( output_path : str , file_name : str , ** kwargs ) -> None : \"\"\"Creates networkx graph from OpenDSS model using Ditto. Args: output_path (str): Path to store the networkx data in json file format file_name (str): JSON file name used to export the network kwargs (dict): Keyword arguments accepted by Ditto \"\"\" try : output_path = Path ( output_path ) return _create_networkx_from_ditto ( output_path , file_name , ** kwargs ) finally : for file_path in output_path . iterdir (): if file_path . suffix == \".adjlist\" : file_path . unlink ( missing_ok = True ) create_networkx_from_json ( json_file_path ) Returns networkx graph from JSON file. Source code in erad\\utils\\ditto_utils.py 249 250 251 252 def create_networkx_from_json ( json_file_path : str ): \"\"\"Returns networkx graph from JSON file.\"\"\" content = read_file ( json_file_path ) return json_graph . adjacency_graph ( content ) download_aws_dir ( bucket , path , target , unsigned = True , ** kwargs ) Utility function download data from AWS S3 directory. Parameters: Name Type Description Default bucket str Name of the bucket. required path str S3 bucket prefix required target str Path for downloading the data required unsigned bool Indicate whether to use credential or not True kwargs dict Keyword arguments accepted by boto3.client required Source code in erad\\utils\\ditto_utils.py 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 @timeit def download_aws_dir ( bucket : str , path : str , target : str , unsigned = True , ** kwargs ) -> None : \"\"\"Utility function download data from AWS S3 directory. Args: bucket (str): Name of the bucket. path (str): S3 bucket prefix target (str): Path for downloading the data unsigned (bool): Indicate whether to use credential or not kwargs (dict): Keyword arguments accepted by `boto3.client` \"\"\" target = Path ( target ) if unsigned : client = boto3 . client ( \"s3\" , config = Config ( signature_version = UNSIGNED )) else : if kwargs : client = boto3 . client ( \"s3\" , ** kwargs ) else : client = boto3 . client ( \"s3\" ) # Handle missing / at end of prefix if not path . endswith ( \"/\" ): path += \"/\" paginator = client . get_paginator ( \"list_objects_v2\" ) for result in paginator . paginate ( Bucket = bucket , Prefix = path ): # Download each file individually for key in result [ \"Contents\" ]: # Calculate relative path rel_path = key [ \"Key\" ][ len ( path ) :] # Skip paths ending in / if not key [ \"Key\" ] . endswith ( \"/\" ): local_file_path = target / rel_path local_file_path . parent . mkdir ( parents = True , exist_ok = True ) client . download_file ( bucket , key [ \"Key\" ], str ( local_file_path )) download_smartds_data ( smartds_region , output_path = './smart_ds_downloads' , year = 2018 , area = 'SFO' , s3_bucket_name = 'oedi-data-lake' , folder_name = 'opendss_no_loadshapes' , cache_folder = 'cache' ) Utility function to download SMARTDS data from AWS S3 bucket. Parameters: Name Type Description Default smartds_region str SMARTDS region name required output_path str Path for downloaded data './smart_ds_downloads' year int Valid year input for downloading the data 2018 area str Valid SMARTDS area 'SFO' s3_bucket_name str S3 bucket name storing the SMARTDS data 'oedi-data-lake' folder_name str S3 bucket folder to download 'opendss_no_loadshapes' cache_folder str Folder path for caching the results 'cache' Raises: Type Description SMARTDSInvalidInput Raises this error if year and/or area provided is not valid. Returns: Name Type Description str str Folder path containing downloaded data. Source code in erad\\utils\\ditto_utils.py 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 @timeit def download_smartds_data ( smartds_region : str , output_path : str = \"./smart_ds_downloads\" , year : int = 2018 , area : str = \"SFO\" , s3_bucket_name : str = \"oedi-data-lake\" , folder_name : str = \"opendss_no_loadshapes\" , cache_folder : str = \"cache\" , ) -> str : \"\"\"Utility function to download SMARTDS data from AWS S3 bucket. Args: smartds_region (str): SMARTDS region name output_path (str): Path for downloaded data year (int): Valid year input for downloading the data area (str): Valid SMARTDS area s3_bucket_name (str): S3 bucket name storing the SMARTDS data folder_name (str): S3 bucket folder to download cache_folder (str): Folder path for caching the results Raises: SMARTDSInvalidInput: Raises this error if year and/or area provided is not valid. Returns: str: Folder path containing downloaded data. \"\"\" if year not in SMARTDS_VALID_YEARS or area not in SMARTDS_VALID_AREAS : raise SMARTDSInvalidInput ( f \"Not valid input! year= { year } area= { area } , \\ valid_years= { SMARTDS_VALID_YEARS } , valid_areas= { SMARTDS_VALID_AREAS } \" ) output_path = Path ( output_path ) cache_folder = Path ( cache_folder ) output_path . mkdir ( exist_ok = True ) cache_folder . mkdir ( exist_ok = True ) cache_key = ( f \" { smartds_region } __ { year } __ { area } __ { s3_bucket_name } _ { folder_name } \" ) cache_data_folder = cache_folder / cache_key output_folder = output_path / cache_key if cache_data_folder . exists (): logger . info ( f \"Cache hit for { cache_data_folder } \" ) shutil . copytree ( cache_data_folder , output_folder , dirs_exist_ok = True ) else : logger . info ( f \"Cache missed reaching to AWS for downloading the data ...\" ) output_folder . mkdir ( exist_ok = True ) prefix = f \"SMART-DS/v1.0/ { year } / { area } / { smartds_region } /scenarios/base_timeseries/ { folder_name } /\" download_aws_dir ( s3_bucket_name , prefix , output_folder ) shutil . copytree ( output_folder , cache_data_folder , dirs_exist_ok = False ) logger . info ( f \"Check the folder { output_folder } for downloaded data\" ) return output_folder","title":"utils.ditto_utils"},{"location":"utils_ditto_utils/#erad.utils.ditto_utils.create_networkx_from_ditto","text":"Creates networkx graph from OpenDSS model using Ditto. Parameters: Name Type Description Default output_path str Path to store the networkx data in json file format required file_name str JSON file name used to export the network required kwargs dict Keyword arguments accepted by Ditto required Source code in erad\\utils\\ditto_utils.py 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 def create_networkx_from_ditto ( output_path : str , file_name : str , ** kwargs ) -> None : \"\"\"Creates networkx graph from OpenDSS model using Ditto. Args: output_path (str): Path to store the networkx data in json file format file_name (str): JSON file name used to export the network kwargs (dict): Keyword arguments accepted by Ditto \"\"\" try : output_path = Path ( output_path ) return _create_networkx_from_ditto ( output_path , file_name , ** kwargs ) finally : for file_path in output_path . iterdir (): if file_path . suffix == \".adjlist\" : file_path . unlink ( missing_ok = True )","title":"create_networkx_from_ditto()"},{"location":"utils_ditto_utils/#erad.utils.ditto_utils.create_networkx_from_json","text":"Returns networkx graph from JSON file. Source code in erad\\utils\\ditto_utils.py 249 250 251 252 def create_networkx_from_json ( json_file_path : str ): \"\"\"Returns networkx graph from JSON file.\"\"\" content = read_file ( json_file_path ) return json_graph . adjacency_graph ( content )","title":"create_networkx_from_json()"},{"location":"utils_ditto_utils/#erad.utils.ditto_utils.download_aws_dir","text":"Utility function download data from AWS S3 directory. Parameters: Name Type Description Default bucket str Name of the bucket. required path str S3 bucket prefix required target str Path for downloading the data required unsigned bool Indicate whether to use credential or not True kwargs dict Keyword arguments accepted by boto3.client required Source code in erad\\utils\\ditto_utils.py 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 @timeit def download_aws_dir ( bucket : str , path : str , target : str , unsigned = True , ** kwargs ) -> None : \"\"\"Utility function download data from AWS S3 directory. Args: bucket (str): Name of the bucket. path (str): S3 bucket prefix target (str): Path for downloading the data unsigned (bool): Indicate whether to use credential or not kwargs (dict): Keyword arguments accepted by `boto3.client` \"\"\" target = Path ( target ) if unsigned : client = boto3 . client ( \"s3\" , config = Config ( signature_version = UNSIGNED )) else : if kwargs : client = boto3 . client ( \"s3\" , ** kwargs ) else : client = boto3 . client ( \"s3\" ) # Handle missing / at end of prefix if not path . endswith ( \"/\" ): path += \"/\" paginator = client . get_paginator ( \"list_objects_v2\" ) for result in paginator . paginate ( Bucket = bucket , Prefix = path ): # Download each file individually for key in result [ \"Contents\" ]: # Calculate relative path rel_path = key [ \"Key\" ][ len ( path ) :] # Skip paths ending in / if not key [ \"Key\" ] . endswith ( \"/\" ): local_file_path = target / rel_path local_file_path . parent . mkdir ( parents = True , exist_ok = True ) client . download_file ( bucket , key [ \"Key\" ], str ( local_file_path ))","title":"download_aws_dir()"},{"location":"utils_ditto_utils/#erad.utils.ditto_utils.download_smartds_data","text":"Utility function to download SMARTDS data from AWS S3 bucket. Parameters: Name Type Description Default smartds_region str SMARTDS region name required output_path str Path for downloaded data './smart_ds_downloads' year int Valid year input for downloading the data 2018 area str Valid SMARTDS area 'SFO' s3_bucket_name str S3 bucket name storing the SMARTDS data 'oedi-data-lake' folder_name str S3 bucket folder to download 'opendss_no_loadshapes' cache_folder str Folder path for caching the results 'cache' Raises: Type Description SMARTDSInvalidInput Raises this error if year and/or area provided is not valid. Returns: Name Type Description str str Folder path containing downloaded data. Source code in erad\\utils\\ditto_utils.py 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 @timeit def download_smartds_data ( smartds_region : str , output_path : str = \"./smart_ds_downloads\" , year : int = 2018 , area : str = \"SFO\" , s3_bucket_name : str = \"oedi-data-lake\" , folder_name : str = \"opendss_no_loadshapes\" , cache_folder : str = \"cache\" , ) -> str : \"\"\"Utility function to download SMARTDS data from AWS S3 bucket. Args: smartds_region (str): SMARTDS region name output_path (str): Path for downloaded data year (int): Valid year input for downloading the data area (str): Valid SMARTDS area s3_bucket_name (str): S3 bucket name storing the SMARTDS data folder_name (str): S3 bucket folder to download cache_folder (str): Folder path for caching the results Raises: SMARTDSInvalidInput: Raises this error if year and/or area provided is not valid. Returns: str: Folder path containing downloaded data. \"\"\" if year not in SMARTDS_VALID_YEARS or area not in SMARTDS_VALID_AREAS : raise SMARTDSInvalidInput ( f \"Not valid input! year= { year } area= { area } , \\ valid_years= { SMARTDS_VALID_YEARS } , valid_areas= { SMARTDS_VALID_AREAS } \" ) output_path = Path ( output_path ) cache_folder = Path ( cache_folder ) output_path . mkdir ( exist_ok = True ) cache_folder . mkdir ( exist_ok = True ) cache_key = ( f \" { smartds_region } __ { year } __ { area } __ { s3_bucket_name } _ { folder_name } \" ) cache_data_folder = cache_folder / cache_key output_folder = output_path / cache_key if cache_data_folder . exists (): logger . info ( f \"Cache hit for { cache_data_folder } \" ) shutil . copytree ( cache_data_folder , output_folder , dirs_exist_ok = True ) else : logger . info ( f \"Cache missed reaching to AWS for downloading the data ...\" ) output_folder . mkdir ( exist_ok = True ) prefix = f \"SMART-DS/v1.0/ { year } / { area } / { smartds_region } /scenarios/base_timeseries/ { folder_name } /\" download_aws_dir ( s3_bucket_name , prefix , output_folder ) shutil . copytree ( output_folder , cache_data_folder , dirs_exist_ok = False ) logger . info ( f \"Check the folder { output_folder } for downloaded data\" ) return output_folder","title":"download_smartds_data()"},{"location":"utils_hifld_utils/","text":"Module for parsing Homeland infrastructure foundation level-data. Idea is to take the bounding box and find the subset of infrastructure in that region. get_relationship_between_hifld_infrastructures ( hifld_data_csv , unique_id_column , load_csv , bus_csv , output_csv_path , distance_threshold = 2000.0 ) Creates a relationship between consumers and HIFLD infrastructures. Parameters: Name Type Description Default hifld_data_csv str Path to filtered HIFLD data csv file required unique_id_column List Column name used as identifier for critical infrastructures required load_csv str Path to load csv file required bus_csv str Path to bus csv file required output_csv_path str output csv path for storing relationship csv required distance_threshold float Distance threshold used for mapping customer to critical infrastructure 2000.0 Source code in erad\\utils\\hifld_utils.py 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 def get_relationship_between_hifld_infrastructures ( hifld_data_csv : str , unique_id_column : str , load_csv : str , bus_csv : str , output_csv_path : str , distance_threshold : float = 2000.0 , ): \"\"\"Creates a relationship between consumers and HIFLD infrastructures. Args: hifld_data_csv (str): Path to filtered HIFLD data csv file unique_id_column (List): Column name used as identifier for critical infrastructures load_csv (str): Path to load csv file bus_csv (str): Path to bus csv file output_csv_path (str): output csv path for storing relationship csv distance_threshold (float): Distance threshold used for mapping customer to critical infrastructure \"\"\" hifld_data_csv = Path ( hifld_data_csv ) bus_csv = Path ( bus_csv ) load_csv = Path ( load_csv ) output_csv_path = Path ( output_csv_path ) path_validation ( hifld_data_csv , check_for_file = True , check_for_file_type = \".csv\" ) path_validation ( bus_csv , check_for_file = True , check_for_file_type = \".csv\" ) path_validation ( load_csv , check_for_file = True , check_for_file_type = \".csv\" ) path_validation ( output_csv_path . parents [ 0 ]) hifld_data_df = pd . read_csv ( hifld_data_csv ) load_df = pd . read_csv ( load_csv ) bus_df = pd . read_csv ( bus_csv ) merged_data = pd . merge ( load_df , bus_df , how = \"left\" , left_on = \"source\" , right_on = \"name\" ) . to_dict ( orient = \"records\" ) # Container for storing shelter relationships _relationship = [] for _record in hifld_data_df . to_dict ( orient = \"records\" ): _lon , _lat = _record [ \"LONGITUDE\" ], _record [ \"LATITUDE\" ] # convert into state plane coordinates _lon_translated , _lat_translated = stateplane . from_lonlat ( _lon , _lat ) # Loop through all the loads for load_record in merged_data : load_lon , load_lat = ( load_record [ \"longitude\" ], load_record [ \"latitude\" ], ) # convert into state plane coordinates load_lon_translated , load_lat_translated = stateplane . from_lonlat ( load_lon , load_lat ) # computes distance distance = math . sqrt ( ( _lat_translated - load_lat_translated ) ** 2 + ( _lon_translated - load_lon_translated ) ** 2 ) if distance < distance_threshold : _relationship . append ( { unique_id_column : _record [ unique_id_column ], \"load_name\" : load_record [ \"name_x\" ], \"distance\" : distance , } ) df = pd . DataFrame ( _relationship ) df . to_csv ( output_csv_path ) get_subset_of_hifld_data ( csv_file , bounds , output_folder , logitude_column_name = 'X' , latitude_column_name = 'Y' , columns_to_keep = [ 'X' , 'Y' ], name_of_csv_file = None ) Extracts a subset of HIFLD data set. Parameters: Name Type Description Default csv_file str Path to HIFLD data csv file required bounds List Bounding box coordinates required output_folder str Path to output folder required logitude_column_name str Expects column with name 'X' 'X' latitude_column_name str Expects column with name 'Y' 'Y' columns_to_keep List List of column names to keep by default keeps all of them ['X', 'Y'] name_of_csv_file (Union[str, None]): Name of csv file to export filtered set Source code in erad\\utils\\hifld_utils.py 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 def get_subset_of_hifld_data ( csv_file : str , bounds : List , output_folder : str , logitude_column_name : str = \"X\" , latitude_column_name : str = \"Y\" , columns_to_keep : List [ str ] = [ \"X\" , \"Y\" ], name_of_csv_file : Union [ str , None ] = None , ) -> None : \"\"\"Extracts a subset of HIFLD data set. Args: csv_file (str): Path to HIFLD data csv file bounds (List): Bounding box coordinates output_folder (str): Path to output folder logitude_column_name (str): Expects column with name 'X' latitude_column_name (str): Expects column with name 'Y' columns_to_keep (List): List of column names to keep by default keeps all of them name_of_csv_file (Union[str, None]): Name of csv file to export filtered set \"\"\" # Unpacking the bounds data longitude_min , latitude_min , longitude_max , latitude_max = bounds # Do a path validation csv_file = Path ( csv_file ) output_folder = Path ( output_folder ) path_validation ( csv_file , check_for_file = True , check_for_file_type = \".csv\" ) path_validation ( output_folder ) # Reading the hifld csv data df = pd . read_csv ( csv_file ) # filtering for bounds df_filtered = df [ ( df [ logitude_column_name ] >= longitude_min ) & ( df [ logitude_column_name ] <= longitude_max ) & ( df [ latitude_column_name ] >= latitude_min ) & ( df [ latitude_column_name ] <= latitude_max ) ] # Keep only the limited columns df_subset = df_filtered [ columns_to_keep ] # export the subset file_name = name_of_csv_file if name_of_csv_file else csv_file . name df_subset . to_csv ( output_folder / file_name )","title":"utils.hifld_utils"},{"location":"utils_hifld_utils/#erad.utils.hifld_utils.get_relationship_between_hifld_infrastructures","text":"Creates a relationship between consumers and HIFLD infrastructures. Parameters: Name Type Description Default hifld_data_csv str Path to filtered HIFLD data csv file required unique_id_column List Column name used as identifier for critical infrastructures required load_csv str Path to load csv file required bus_csv str Path to bus csv file required output_csv_path str output csv path for storing relationship csv required distance_threshold float Distance threshold used for mapping customer to critical infrastructure 2000.0 Source code in erad\\utils\\hifld_utils.py 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 def get_relationship_between_hifld_infrastructures ( hifld_data_csv : str , unique_id_column : str , load_csv : str , bus_csv : str , output_csv_path : str , distance_threshold : float = 2000.0 , ): \"\"\"Creates a relationship between consumers and HIFLD infrastructures. Args: hifld_data_csv (str): Path to filtered HIFLD data csv file unique_id_column (List): Column name used as identifier for critical infrastructures load_csv (str): Path to load csv file bus_csv (str): Path to bus csv file output_csv_path (str): output csv path for storing relationship csv distance_threshold (float): Distance threshold used for mapping customer to critical infrastructure \"\"\" hifld_data_csv = Path ( hifld_data_csv ) bus_csv = Path ( bus_csv ) load_csv = Path ( load_csv ) output_csv_path = Path ( output_csv_path ) path_validation ( hifld_data_csv , check_for_file = True , check_for_file_type = \".csv\" ) path_validation ( bus_csv , check_for_file = True , check_for_file_type = \".csv\" ) path_validation ( load_csv , check_for_file = True , check_for_file_type = \".csv\" ) path_validation ( output_csv_path . parents [ 0 ]) hifld_data_df = pd . read_csv ( hifld_data_csv ) load_df = pd . read_csv ( load_csv ) bus_df = pd . read_csv ( bus_csv ) merged_data = pd . merge ( load_df , bus_df , how = \"left\" , left_on = \"source\" , right_on = \"name\" ) . to_dict ( orient = \"records\" ) # Container for storing shelter relationships _relationship = [] for _record in hifld_data_df . to_dict ( orient = \"records\" ): _lon , _lat = _record [ \"LONGITUDE\" ], _record [ \"LATITUDE\" ] # convert into state plane coordinates _lon_translated , _lat_translated = stateplane . from_lonlat ( _lon , _lat ) # Loop through all the loads for load_record in merged_data : load_lon , load_lat = ( load_record [ \"longitude\" ], load_record [ \"latitude\" ], ) # convert into state plane coordinates load_lon_translated , load_lat_translated = stateplane . from_lonlat ( load_lon , load_lat ) # computes distance distance = math . sqrt ( ( _lat_translated - load_lat_translated ) ** 2 + ( _lon_translated - load_lon_translated ) ** 2 ) if distance < distance_threshold : _relationship . append ( { unique_id_column : _record [ unique_id_column ], \"load_name\" : load_record [ \"name_x\" ], \"distance\" : distance , } ) df = pd . DataFrame ( _relationship ) df . to_csv ( output_csv_path )","title":"get_relationship_between_hifld_infrastructures()"},{"location":"utils_hifld_utils/#erad.utils.hifld_utils.get_subset_of_hifld_data","text":"Extracts a subset of HIFLD data set. Parameters: Name Type Description Default csv_file str Path to HIFLD data csv file required bounds List Bounding box coordinates required output_folder str Path to output folder required logitude_column_name str Expects column with name 'X' 'X' latitude_column_name str Expects column with name 'Y' 'Y' columns_to_keep List List of column names to keep by default keeps all of them ['X', 'Y'] name_of_csv_file (Union[str, None]): Name of csv file to export filtered set Source code in erad\\utils\\hifld_utils.py 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 def get_subset_of_hifld_data ( csv_file : str , bounds : List , output_folder : str , logitude_column_name : str = \"X\" , latitude_column_name : str = \"Y\" , columns_to_keep : List [ str ] = [ \"X\" , \"Y\" ], name_of_csv_file : Union [ str , None ] = None , ) -> None : \"\"\"Extracts a subset of HIFLD data set. Args: csv_file (str): Path to HIFLD data csv file bounds (List): Bounding box coordinates output_folder (str): Path to output folder logitude_column_name (str): Expects column with name 'X' latitude_column_name (str): Expects column with name 'Y' columns_to_keep (List): List of column names to keep by default keeps all of them name_of_csv_file (Union[str, None]): Name of csv file to export filtered set \"\"\" # Unpacking the bounds data longitude_min , latitude_min , longitude_max , latitude_max = bounds # Do a path validation csv_file = Path ( csv_file ) output_folder = Path ( output_folder ) path_validation ( csv_file , check_for_file = True , check_for_file_type = \".csv\" ) path_validation ( output_folder ) # Reading the hifld csv data df = pd . read_csv ( csv_file ) # filtering for bounds df_filtered = df [ ( df [ logitude_column_name ] >= longitude_min ) & ( df [ logitude_column_name ] <= longitude_max ) & ( df [ latitude_column_name ] >= latitude_min ) & ( df [ latitude_column_name ] <= latitude_max ) ] # Keep only the limited columns df_subset = df_filtered [ columns_to_keep ] # export the subset file_name = name_of_csv_file if name_of_csv_file else csv_file . name df_subset . to_csv ( output_folder / file_name )","title":"get_subset_of_hifld_data()"},{"location":"utils_opendss_utils/","text":"Module for extracting assets from OpenDSS model. Examples: >>> from erad import utils >>> extract_opendss_model ( <path_to_opendss_master_file>, <output_folder> ) execute_dss_command ( dss_instance , dss_command ) Pass the valid dss command to be executed. Parameters: Name Type Description Default dss_instance dss OpenDSS instance with models preloaded required dss_command str DSS command sring to be executed required Raises: Type Description OpenDSSCommandError Raises this because opendss command execution ran into error Source code in erad\\utils\\opendss_utils.py 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 def execute_dss_command ( dss_instance : dss , dss_command : str ) -> None : \"\"\"Pass the valid dss command to be executed. Args: dss_instance (dss): OpenDSS instance with models preloaded dss_command (str): DSS command sring to be executed Raises: OpenDSSCommandError: Raises this because opendss command execution ran into error \"\"\" error = dss_instance . run_command ( dss_command ) if error : logger . error ( f \"Error executing command { dss_command } >> { error } \" ) raise OpenDSSCommandError ( f \"Error executing command { dss_command } >> { error } \" ) logger . info ( f \"Sucessfully executed the command, { dss_command } \" ) extract_export_opendss_model ( master_file , output_folder_path ) Extract the opendss models and exports into csv file format. Parameters: Name Type Description Default master_file str Path to opendss master file required output_folder_path str Folder path for exporting the models to. required Source code in erad\\utils\\opendss_utils.py 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 def extract_export_opendss_model ( master_file : str , output_folder_path : str ) -> None : \"\"\"Extract the opendss models and exports into csv file format. Args: master_file (str): Path to opendss master file output_folder_path (str): Folder path for exporting the models to. \"\"\" # Do a basic check on the path master_file = Path ( master_file ) path_validation ( master_file ) logger . debug ( f \"Attempting to read case file >> { master_file } \" ) # Clear memory and compile dss file dss . run_command ( \"Clear\" ) dss . Basic . ClearAll () execute_dss_command ( dss , f \"Redirect { master_file } \" ) # Initial container transformers = get_transformers ( dss ) line_sections = get_line_sections ( dss ) buses = get_buses ( dss ) capacitors = get_capacitors ( dss ) pv_systems = get_pvsystems ( dss ) loads = get_loads ( dss ) output_folder_path = Path ( output_folder_path ) output_folder_path . mkdir ( exist_ok = True ) transformers_df = pd . DataFrame ( transformers ) transformers_df . to_csv ( output_folder_path / \"transformers.csv\" ) line_sections_df = pd . DataFrame ( line_sections ) line_sections_df . to_csv ( output_folder_path / \"line_sections.csv\" ) buses_df = pd . DataFrame ( buses ) buses_df . to_csv ( output_folder_path / \"buses.csv\" ) capacitors_df = pd . DataFrame ( capacitors ) capacitors_df . to_csv ( output_folder_path / \"capacitors.csv\" ) pv_systems_df = pd . DataFrame ( pv_systems ) pv_systems_df . to_csv ( output_folder_path / \"pv_systems.csv\" ) loads_df = pd . DataFrame ( loads ) loads_df . to_csv ( output_folder_path / \"loads.csv\" ) get_bounding_box ( master_file , buffer = 1000 ) Creates a bounding box coordinate for covering region of opendss model. Parameters: Name Type Description Default master_file str Path to master dss file required buffer float Buffer distance around distribution model in meter 1000 Raises: Type Description MultiStatePlaneError Raises this if opendss models lies in multiple state plane coordinates Returns: Name Type Description List List List of bounding box coordinates (lower_left, upper_right) Source code in erad\\utils\\opendss_utils.py 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 def get_bounding_box ( master_file : str , buffer : float = 1000 ) -> List : \"\"\"Creates a bounding box coordinate for covering region of opendss model. Args: master_file (str): Path to master dss file buffer (float): Buffer distance around distribution model in meter Raises: MultiStatePlaneError: Raises this if opendss models lies in multiple state plane coordinates Returns: List: List of bounding box coordinates (lower_left, upper_right) \"\"\" # Get bounding box for opendss network # Do a basic check on the path master_file = Path ( master_file ) path_validation ( master_file ) logger . debug ( f \"Attempting to read case file >> { master_file } \" ) # Clear memory and compile dss file dss . run_command ( \"Clear\" ) dss . Basic . ClearAll () execute_dss_command ( dss , f \"Redirect { master_file } \" ) # Get all the points points = [] for bus in dss . Circuit . AllBusNames (): dss . Circuit . SetActiveBus ( bus ) points . append ([ dss . Bus . X (), dss . Bus . Y ()]) # Create a multipoint to get bounds multi_points = MultiPoint ( points ) bounds = multi_points . bounds # Get EPSG value for converting into coordinate reference system if stateplane . identify ( bounds [ 0 ], bounds [ 1 ]) != stateplane . identify ( bounds [ 2 ], bounds [ 3 ] ): raise MultiStatePlaneError ( f \"The regions uses multiple stateplane coordinate system\" ) epsg_value = stateplane . identify ( bounds [ 0 ], bounds [ 1 ]) # Let's project all the WGS84 coordinates into # transformed coordinates this will make sure distance is in meter transformed_points = [ stateplane . from_lonlat ( * point , epsg_value ) for point in points ] # Create a multipoint from the transformed coordinates transformed_multipoint = MultiPoint ( transformed_points ) . buffer ( buffer ) # Get the bounds and convert back to wsg84 format transformed_bounds = transformed_multipoint . bounds bounds_wsg84 = stateplane . to_lonlat ( transformed_bounds [ 0 ], transformed_bounds [ 1 ], epsg_value ) + stateplane . to_lonlat ( transformed_bounds [ 2 ], transformed_bounds [ 3 ], epsg_value ) return bounds_wsg84 get_buses ( dss_instance ) Function to return list of all buses in opendss model. Parameters: Name Type Description Default dss_instance dss OpenDSS instance with models preloaded required Returns: Name Type Description List List List of bus metadata object Source code in erad\\utils\\opendss_utils.py 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 def get_buses ( dss_instance : dss ) -> List : \"\"\"Function to return list of all buses in opendss model. Args: dss_instance (dss): OpenDSS instance with models preloaded Returns: List: List of bus metadata object \"\"\" buses_container = [] for bus in dss_instance . Circuit . AllBusNames (): dss_instance . Circuit . SetActiveBus ( bus ) buses_container . append ( { \"name\" : bus , \"type\" : \"Bus\" , \"kv\" : dss_instance . Bus . kVBase (), \"longitude\" : dss_instance . Bus . X (), \"latitude\" : dss_instance . Bus . Y (), } ) return buses_container get_capacitors ( dss_instance ) Function to return list of all capacitors in opendss model. Parameters: Name Type Description Default dss_instance dss OpenDSS instance with models preloaded required Returns: Name Type Description List List List of capacitor metadata object Source code in erad\\utils\\opendss_utils.py 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 def get_capacitors ( dss_instance : dss ) -> List : \"\"\"Function to return list of all capacitors in opendss model. Args: dss_instance (dss): OpenDSS instance with models preloaded Returns: List: List of capacitor metadata object \"\"\" capacitors_container = [] dss_instance . Circuit . SetActiveClass ( \"Capacitor\" ) flag = dss_instance . ActiveClass . First () while flag > 0 : capacitor_name = dss_instance . CktElement . Name () . lower () buses = dss_instance . CktElement . BusNames () bus1 = buses [ 0 ] . split ( \".\" )[ 0 ] capacitors_container . append ( { \"name\" : capacitor_name , \"type\" : \"Capacitor\" , \"source\" : bus1 , \"kv\" : dss_instance . Capacitors . kV (), \"kvar\" : dss_instance . Capacitors . kvar (), } ) flag = dss_instance . ActiveClass . Next () return capacitors_container get_line_sections ( dss_instance ) Function to return list of all line segments in opendss model. Parameters: Name Type Description Default dss_instance dss OpenDSS instance with models preloaded required Returns: Name Type Description List List List of line segment metadata object Source code in erad\\utils\\opendss_utils.py 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 def get_line_sections ( dss_instance : dss ) -> List : \"\"\"Function to return list of all line segments in opendss model. Args: dss_instance (dss): OpenDSS instance with models preloaded Returns: List: List of line segment metadata object \"\"\" UNIT_MAPPER = { 0 : 0 , 1 : 1.60934 , 2 : 0.3048 , 3 : 1 , 4 : 0.001 , 5 : 0.0003048 , 6 : 0.0000254 , 7 : 0.00001 , } sections_container = [] dss_instance . Circuit . SetActiveClass ( \"Line\" ) flag = dss_instance . ActiveClass . First () while flag > 0 : section_name = dss_instance . CktElement . Name () . lower () buses = dss_instance . CktElement . BusNames () bus1 , bus2 = buses [ 0 ] . split ( \".\" )[ 0 ], buses [ 1 ] . split ( \".\" )[ 0 ] sections_container . append ( { \"name\" : section_name , \"type\" : \"LineSegment\" , \"source\" : bus1 , \"target\" : bus2 , \"length_km\" : UNIT_MAPPER [ dss_instance . Lines . Units ()] * dss_instance . Lines . Length (), \"ampacity\" : dss_instance . Lines . NormAmps (), \"num_phase\" : dss_instance . CktElement . NumPhases (), } ) flag = dss_instance . ActiveClass . Next () return sections_container get_loads ( dss_instance ) Function to return list of all loads in opendss model. Parameters: Name Type Description Default dss_instance dss OpenDSS instance with models preloaded required Returns: Name Type Description List List of load metadata object Source code in erad\\utils\\opendss_utils.py 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 def get_loads ( dss_instance ): \"\"\"Function to return list of all loads in opendss model. Args: dss_instance (dss): OpenDSS instance with models preloaded Returns: List: List of load metadata object \"\"\" loads_container = [] dss_instance . Circuit . SetActiveClass ( \"Load\" ) flag = dss_instance . ActiveClass . First () while flag > 0 : load_name = dss_instance . CktElement . Name () . lower () buses = dss_instance . CktElement . BusNames () bus1 = buses [ 0 ] . split ( \".\" )[ 0 ] loads_container . append ( { \"name\" : load_name , \"type\" : \"Load\" , \"source\" : bus1 , \"kw\" : dss_instance . Loads . kW (), \"kvar\" : dss_instance . Loads . kvar (), } ) flag = dss_instance . ActiveClass . Next () return loads_container get_pvsystems ( dss_instance ) Function to return list of all pv systems in opendss model. Parameters: Name Type Description Default dss_instance dss OpenDSS instance with models preloaded required Returns: Name Type Description List List List of PVsystem metadata object Source code in erad\\utils\\opendss_utils.py 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 def get_pvsystems ( dss_instance : dss ) -> List : \"\"\"Function to return list of all pv systems in opendss model. Args: dss_instance (dss): OpenDSS instance with models preloaded Returns: List: List of PVsystem metadata object \"\"\" pvs_container = [] dss_instance . Circuit . SetActiveClass ( \"PVSystem\" ) flag = dss_instance . ActiveClass . First () while flag > 0 : pv_name = dss_instance . CktElement . Name () . lower () buses = dss_instance . CktElement . BusNames () bus1 = buses [ 0 ] . split ( \".\" )[ 0 ] pvs_container . append ( { \"name\" : pv_name , \"type\" : \"PVSystem\" , \"source\" : bus1 , \"rated_power\" : dss_instance . PVSystems . Pmpp (), } ) flag = dss_instance . ActiveClass . Next () return pvs_container get_transformers ( dss_instance ) Function to return list of transformers in opendss models. Parameters: Name Type Description Default dss_instance dss OpenDSS instance with models preloaded required Returns: Name Type Description List List List of transformer metadata object Source code in erad\\utils\\opendss_utils.py 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 def get_transformers ( dss_instance : dss ) -> List : \"\"\"Function to return list of transformers in opendss models. Args: dss_instance (dss): OpenDSS instance with models preloaded Returns: List: List of transformer metadata object \"\"\" transformer_container = [] dss_instance . Circuit . SetActiveClass ( \"Transformer\" ) flag = dss_instance . ActiveClass . First () while flag > 0 : trans_name = dss_instance . CktElement . Name () . lower () buses = dss_instance . CktElement . BusNames () bus1 , bus2 = buses [ 0 ] . split ( \".\" )[ 0 ], buses [ 1 ] . split ( \".\" )[ 0 ] transformer_container . append ( { \"name\" : trans_name , \"type\" : \"Transformer\" , \"source\" : bus1 , \"target\" : bus2 , \"kva\" : dss_instance . Transformers . kVA (), \"num_phase\" : dss_instance . CktElement . NumPhases (), } ) flag = dss_instance . ActiveClass . Next () return transformer_container","title":"utils.opendss_utils"},{"location":"utils_opendss_utils/#erad.utils.opendss_utils.execute_dss_command","text":"Pass the valid dss command to be executed. Parameters: Name Type Description Default dss_instance dss OpenDSS instance with models preloaded required dss_command str DSS command sring to be executed required Raises: Type Description OpenDSSCommandError Raises this because opendss command execution ran into error Source code in erad\\utils\\opendss_utils.py 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 def execute_dss_command ( dss_instance : dss , dss_command : str ) -> None : \"\"\"Pass the valid dss command to be executed. Args: dss_instance (dss): OpenDSS instance with models preloaded dss_command (str): DSS command sring to be executed Raises: OpenDSSCommandError: Raises this because opendss command execution ran into error \"\"\" error = dss_instance . run_command ( dss_command ) if error : logger . error ( f \"Error executing command { dss_command } >> { error } \" ) raise OpenDSSCommandError ( f \"Error executing command { dss_command } >> { error } \" ) logger . info ( f \"Sucessfully executed the command, { dss_command } \" )","title":"execute_dss_command()"},{"location":"utils_opendss_utils/#erad.utils.opendss_utils.extract_export_opendss_model","text":"Extract the opendss models and exports into csv file format. Parameters: Name Type Description Default master_file str Path to opendss master file required output_folder_path str Folder path for exporting the models to. required Source code in erad\\utils\\opendss_utils.py 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 def extract_export_opendss_model ( master_file : str , output_folder_path : str ) -> None : \"\"\"Extract the opendss models and exports into csv file format. Args: master_file (str): Path to opendss master file output_folder_path (str): Folder path for exporting the models to. \"\"\" # Do a basic check on the path master_file = Path ( master_file ) path_validation ( master_file ) logger . debug ( f \"Attempting to read case file >> { master_file } \" ) # Clear memory and compile dss file dss . run_command ( \"Clear\" ) dss . Basic . ClearAll () execute_dss_command ( dss , f \"Redirect { master_file } \" ) # Initial container transformers = get_transformers ( dss ) line_sections = get_line_sections ( dss ) buses = get_buses ( dss ) capacitors = get_capacitors ( dss ) pv_systems = get_pvsystems ( dss ) loads = get_loads ( dss ) output_folder_path = Path ( output_folder_path ) output_folder_path . mkdir ( exist_ok = True ) transformers_df = pd . DataFrame ( transformers ) transformers_df . to_csv ( output_folder_path / \"transformers.csv\" ) line_sections_df = pd . DataFrame ( line_sections ) line_sections_df . to_csv ( output_folder_path / \"line_sections.csv\" ) buses_df = pd . DataFrame ( buses ) buses_df . to_csv ( output_folder_path / \"buses.csv\" ) capacitors_df = pd . DataFrame ( capacitors ) capacitors_df . to_csv ( output_folder_path / \"capacitors.csv\" ) pv_systems_df = pd . DataFrame ( pv_systems ) pv_systems_df . to_csv ( output_folder_path / \"pv_systems.csv\" ) loads_df = pd . DataFrame ( loads ) loads_df . to_csv ( output_folder_path / \"loads.csv\" )","title":"extract_export_opendss_model()"},{"location":"utils_opendss_utils/#erad.utils.opendss_utils.get_bounding_box","text":"Creates a bounding box coordinate for covering region of opendss model. Parameters: Name Type Description Default master_file str Path to master dss file required buffer float Buffer distance around distribution model in meter 1000 Raises: Type Description MultiStatePlaneError Raises this if opendss models lies in multiple state plane coordinates Returns: Name Type Description List List List of bounding box coordinates (lower_left, upper_right) Source code in erad\\utils\\opendss_utils.py 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 def get_bounding_box ( master_file : str , buffer : float = 1000 ) -> List : \"\"\"Creates a bounding box coordinate for covering region of opendss model. Args: master_file (str): Path to master dss file buffer (float): Buffer distance around distribution model in meter Raises: MultiStatePlaneError: Raises this if opendss models lies in multiple state plane coordinates Returns: List: List of bounding box coordinates (lower_left, upper_right) \"\"\" # Get bounding box for opendss network # Do a basic check on the path master_file = Path ( master_file ) path_validation ( master_file ) logger . debug ( f \"Attempting to read case file >> { master_file } \" ) # Clear memory and compile dss file dss . run_command ( \"Clear\" ) dss . Basic . ClearAll () execute_dss_command ( dss , f \"Redirect { master_file } \" ) # Get all the points points = [] for bus in dss . Circuit . AllBusNames (): dss . Circuit . SetActiveBus ( bus ) points . append ([ dss . Bus . X (), dss . Bus . Y ()]) # Create a multipoint to get bounds multi_points = MultiPoint ( points ) bounds = multi_points . bounds # Get EPSG value for converting into coordinate reference system if stateplane . identify ( bounds [ 0 ], bounds [ 1 ]) != stateplane . identify ( bounds [ 2 ], bounds [ 3 ] ): raise MultiStatePlaneError ( f \"The regions uses multiple stateplane coordinate system\" ) epsg_value = stateplane . identify ( bounds [ 0 ], bounds [ 1 ]) # Let's project all the WGS84 coordinates into # transformed coordinates this will make sure distance is in meter transformed_points = [ stateplane . from_lonlat ( * point , epsg_value ) for point in points ] # Create a multipoint from the transformed coordinates transformed_multipoint = MultiPoint ( transformed_points ) . buffer ( buffer ) # Get the bounds and convert back to wsg84 format transformed_bounds = transformed_multipoint . bounds bounds_wsg84 = stateplane . to_lonlat ( transformed_bounds [ 0 ], transformed_bounds [ 1 ], epsg_value ) + stateplane . to_lonlat ( transformed_bounds [ 2 ], transformed_bounds [ 3 ], epsg_value ) return bounds_wsg84","title":"get_bounding_box()"},{"location":"utils_opendss_utils/#erad.utils.opendss_utils.get_buses","text":"Function to return list of all buses in opendss model. Parameters: Name Type Description Default dss_instance dss OpenDSS instance with models preloaded required Returns: Name Type Description List List List of bus metadata object Source code in erad\\utils\\opendss_utils.py 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 def get_buses ( dss_instance : dss ) -> List : \"\"\"Function to return list of all buses in opendss model. Args: dss_instance (dss): OpenDSS instance with models preloaded Returns: List: List of bus metadata object \"\"\" buses_container = [] for bus in dss_instance . Circuit . AllBusNames (): dss_instance . Circuit . SetActiveBus ( bus ) buses_container . append ( { \"name\" : bus , \"type\" : \"Bus\" , \"kv\" : dss_instance . Bus . kVBase (), \"longitude\" : dss_instance . Bus . X (), \"latitude\" : dss_instance . Bus . Y (), } ) return buses_container","title":"get_buses()"},{"location":"utils_opendss_utils/#erad.utils.opendss_utils.get_capacitors","text":"Function to return list of all capacitors in opendss model. Parameters: Name Type Description Default dss_instance dss OpenDSS instance with models preloaded required Returns: Name Type Description List List List of capacitor metadata object Source code in erad\\utils\\opendss_utils.py 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 def get_capacitors ( dss_instance : dss ) -> List : \"\"\"Function to return list of all capacitors in opendss model. Args: dss_instance (dss): OpenDSS instance with models preloaded Returns: List: List of capacitor metadata object \"\"\" capacitors_container = [] dss_instance . Circuit . SetActiveClass ( \"Capacitor\" ) flag = dss_instance . ActiveClass . First () while flag > 0 : capacitor_name = dss_instance . CktElement . Name () . lower () buses = dss_instance . CktElement . BusNames () bus1 = buses [ 0 ] . split ( \".\" )[ 0 ] capacitors_container . append ( { \"name\" : capacitor_name , \"type\" : \"Capacitor\" , \"source\" : bus1 , \"kv\" : dss_instance . Capacitors . kV (), \"kvar\" : dss_instance . Capacitors . kvar (), } ) flag = dss_instance . ActiveClass . Next () return capacitors_container","title":"get_capacitors()"},{"location":"utils_opendss_utils/#erad.utils.opendss_utils.get_line_sections","text":"Function to return list of all line segments in opendss model. Parameters: Name Type Description Default dss_instance dss OpenDSS instance with models preloaded required Returns: Name Type Description List List List of line segment metadata object Source code in erad\\utils\\opendss_utils.py 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 def get_line_sections ( dss_instance : dss ) -> List : \"\"\"Function to return list of all line segments in opendss model. Args: dss_instance (dss): OpenDSS instance with models preloaded Returns: List: List of line segment metadata object \"\"\" UNIT_MAPPER = { 0 : 0 , 1 : 1.60934 , 2 : 0.3048 , 3 : 1 , 4 : 0.001 , 5 : 0.0003048 , 6 : 0.0000254 , 7 : 0.00001 , } sections_container = [] dss_instance . Circuit . SetActiveClass ( \"Line\" ) flag = dss_instance . ActiveClass . First () while flag > 0 : section_name = dss_instance . CktElement . Name () . lower () buses = dss_instance . CktElement . BusNames () bus1 , bus2 = buses [ 0 ] . split ( \".\" )[ 0 ], buses [ 1 ] . split ( \".\" )[ 0 ] sections_container . append ( { \"name\" : section_name , \"type\" : \"LineSegment\" , \"source\" : bus1 , \"target\" : bus2 , \"length_km\" : UNIT_MAPPER [ dss_instance . Lines . Units ()] * dss_instance . Lines . Length (), \"ampacity\" : dss_instance . Lines . NormAmps (), \"num_phase\" : dss_instance . CktElement . NumPhases (), } ) flag = dss_instance . ActiveClass . Next () return sections_container","title":"get_line_sections()"},{"location":"utils_opendss_utils/#erad.utils.opendss_utils.get_loads","text":"Function to return list of all loads in opendss model. Parameters: Name Type Description Default dss_instance dss OpenDSS instance with models preloaded required Returns: Name Type Description List List of load metadata object Source code in erad\\utils\\opendss_utils.py 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 def get_loads ( dss_instance ): \"\"\"Function to return list of all loads in opendss model. Args: dss_instance (dss): OpenDSS instance with models preloaded Returns: List: List of load metadata object \"\"\" loads_container = [] dss_instance . Circuit . SetActiveClass ( \"Load\" ) flag = dss_instance . ActiveClass . First () while flag > 0 : load_name = dss_instance . CktElement . Name () . lower () buses = dss_instance . CktElement . BusNames () bus1 = buses [ 0 ] . split ( \".\" )[ 0 ] loads_container . append ( { \"name\" : load_name , \"type\" : \"Load\" , \"source\" : bus1 , \"kw\" : dss_instance . Loads . kW (), \"kvar\" : dss_instance . Loads . kvar (), } ) flag = dss_instance . ActiveClass . Next () return loads_container","title":"get_loads()"},{"location":"utils_opendss_utils/#erad.utils.opendss_utils.get_pvsystems","text":"Function to return list of all pv systems in opendss model. Parameters: Name Type Description Default dss_instance dss OpenDSS instance with models preloaded required Returns: Name Type Description List List List of PVsystem metadata object Source code in erad\\utils\\opendss_utils.py 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 def get_pvsystems ( dss_instance : dss ) -> List : \"\"\"Function to return list of all pv systems in opendss model. Args: dss_instance (dss): OpenDSS instance with models preloaded Returns: List: List of PVsystem metadata object \"\"\" pvs_container = [] dss_instance . Circuit . SetActiveClass ( \"PVSystem\" ) flag = dss_instance . ActiveClass . First () while flag > 0 : pv_name = dss_instance . CktElement . Name () . lower () buses = dss_instance . CktElement . BusNames () bus1 = buses [ 0 ] . split ( \".\" )[ 0 ] pvs_container . append ( { \"name\" : pv_name , \"type\" : \"PVSystem\" , \"source\" : bus1 , \"rated_power\" : dss_instance . PVSystems . Pmpp (), } ) flag = dss_instance . ActiveClass . Next () return pvs_container","title":"get_pvsystems()"},{"location":"utils_opendss_utils/#erad.utils.opendss_utils.get_transformers","text":"Function to return list of transformers in opendss models. Parameters: Name Type Description Default dss_instance dss OpenDSS instance with models preloaded required Returns: Name Type Description List List List of transformer metadata object Source code in erad\\utils\\opendss_utils.py 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 def get_transformers ( dss_instance : dss ) -> List : \"\"\"Function to return list of transformers in opendss models. Args: dss_instance (dss): OpenDSS instance with models preloaded Returns: List: List of transformer metadata object \"\"\" transformer_container = [] dss_instance . Circuit . SetActiveClass ( \"Transformer\" ) flag = dss_instance . ActiveClass . First () while flag > 0 : trans_name = dss_instance . CktElement . Name () . lower () buses = dss_instance . CktElement . BusNames () bus1 , bus2 = buses [ 0 ] . split ( \".\" )[ 0 ], buses [ 1 ] . split ( \".\" )[ 0 ] transformer_container . append ( { \"name\" : trans_name , \"type\" : \"Transformer\" , \"source\" : bus1 , \"target\" : bus2 , \"kva\" : dss_instance . Transformers . kVA (), \"num_phase\" : dss_instance . CktElement . NumPhases (), } ) flag = dss_instance . ActiveClass . Next () return transformer_container","title":"get_transformers()"},{"location":"utils_util/","text":"Utility functions that can be used in various parts of the code. path_validation ( file_path , check_for_file = False , check_for_file_type = None ) Utility function for validating the path. Parameters: Name Type Description Default file_path str Path to be validated required check_for_file bool Checks for existence of file False check_for_file_type Union [ str , None] Check if file is of this type None Raises: Type Description PathDoesNotExist Raises if path does not exist NotAFileError Raises if file is not present InvalidFileTypePassed Raises if invalid file type is passed Source code in erad\\utils\\util.py 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 def path_validation ( file_path : str , check_for_file : bool = False , check_for_file_type : Union [ str , None ] = None , ) -> None : \"\"\"Utility function for validating the path. Args: file_path (str): Path to be validated check_for_file (bool): Checks for existence of file check_for_file_type (Union[str, None]): Check if file is of this type Raises: PathDoesNotExist: Raises if path does not exist NotAFileError: Raises if file is not present InvalidFileTypePassed: Raises if invalid file type is passed \"\"\" file_path = Path ( file_path ) if not file_path . exists (): logger . error ( f \" { file_path } does not exist!\" ) raise PathDoesNotExist ( file_path ) if check_for_file and file_path . is_dir (): logger . error ( f \"Expected file but got folder : { file_path } \" ) raise NotAFileError ( file_path ) if check_for_file_type and file_path . suffix != check_for_file_type : raise InvalidFileTypePassed ( file_path , check_for_file_type ) logger . debug ( f \" { file_path } validated successfully!\" ) read_file ( file_path ) Utility function to read file into a python dict. Supports json, yaml and geojson. Parameters: Name Type Description Default file_path str Path to a file to be read. required Raises: Type Description FeatureNotImplementedError Raises if invalid file is passed. Returns: Name Type Description dict dict Python dict containing content of file. Source code in erad\\utils\\util.py 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 @timeit def read_file ( file_path : str ) -> dict : \"\"\"Utility function to read file into a python dict. Supports json, yaml and geojson. Args: file_path (str): Path to a file to be read. Raises: FeatureNotImplementedError: Raises if invalid file is passed. Returns: dict: Python dict containing content of file. \"\"\" file_path = Path ( file_path ) logger . debug ( f \"Attempting to read { file_path } \" ) path_validation ( file_path , check_for_file = True ) # Handle JSON file read if file_path . suffix == \".json\" : with open ( file_path , \"r\" ) as f : content = json . load ( f ) # Handle YAML file read elif file_path . suffix == \".yaml\" : with open ( file_path , \"r\" ) as f : content = yaml . safe_load ( f ) # Handle geojson file read elif file_path . suffix == \".geojson\" : with open ( file_path , \"r\" ) as f : content = geojson . load ( f ) else : logger . error ( f \"Could not read the { file_path } , this feature is not yet implemented\" ) raise FeatureNotImplementedError ( f \"File of type { file_path . suffix } \\ is not yet implemented for reading purpose\" ) logger . debug ( f \" { file_path } read successfully\" ) return content setup_logging ( filename = None ) Creates log directory and sets up logging via logging.yaml. Parameters: Name Type Description Default filename str Path to logging.yaml file None If not providex expects log file in the root of repo. Source code in erad\\utils\\util.py 44 45 46 47 48 49 50 51 52 53 54 55 56 def setup_logging ( filename : Union [ str , None ] = None ) -> None : \"\"\"Creates log directory and sets up logging via logging.yaml. Args: filename (str): Path to logging.yaml file If not providex expects log file in the root of repo. \"\"\" if filename is None : filename = Path ( __file__ ) . parents [ 2 ] / \"logging.yaml\" logging . config . dictConfig ( read_file ( filename )) timeit ( func ) Decorator for timing execution of a function. Source code in erad\\utils\\util.py 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 def timeit ( func ): \"\"\"Decorator for timing execution of a function.\"\"\" def wrapper ( * args , ** kwargs ): time_start = time . perf_counter () logger . debug ( f \"Timing for { func } started\" ) ret_val = func ( * args , ** kwargs ) time_elapsed = time . perf_counter () - time_start # memory_mb =resource.getrusage(resource.RUSAGE_SELF).ru_maxrss/1024.0/1024.0 logger . debug ( f \"Time took to execute the function { func } \\ with args { args } , kwargs { kwargs } is { time_elapsed } seconds\" ) return ret_val return wrapper write_file ( content , file_path , ** kwargs ) Utility function to write to a file.. Supports json, yaml and geojson. Parameters: Name Type Description Default content dict Python dict content required file_path str Path to a file to be read required kwargs dict Keyword arguments passed to relevant writer. required Raises: Type Description FeatureNotImplementedError Raises if invalid file type is passed. Source code in erad\\utils\\util.py 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 def write_file ( content : dict , file_path : str , ** kwargs ) -> None : \"\"\"Utility function to write to a file.. Supports json, yaml and geojson. Args: content (dict): Python dict content file_path (str): Path to a file to be read kwargs (dict): Keyword arguments passed to relevant writer. Raises: FeatureNotImplementedError: Raises if invalid file type is passed. \"\"\" file_path = Path ( file_path ) path_validation ( file_path . parent ) # Handle JSON file write if file_path . suffix == \".json\" : with open ( file_path , \"w\" ) as f : json . dump ( content , f , ** kwargs ) # Handle YAML file write elif file_path . suffix == \".yaml\" : with open ( file_path , \"w\" ) as f : yaml . safe_dump ( content , f , ** kwargs ) # Handle geojson file write elif file_path . suffix == \".geojson\" : with open ( file_path , \"w\" ) as f : geojson . dump ( content , f , ** kwargs ) else : raise FeatureNotImplementedError ( f \"File of type { file_path . suffix } \\ is not yet implemented for writing purpose\" )","title":"utils.util"},{"location":"utils_util/#erad.utils.util.path_validation","text":"Utility function for validating the path. Parameters: Name Type Description Default file_path str Path to be validated required check_for_file bool Checks for existence of file False check_for_file_type Union [ str , None] Check if file is of this type None Raises: Type Description PathDoesNotExist Raises if path does not exist NotAFileError Raises if file is not present InvalidFileTypePassed Raises if invalid file type is passed Source code in erad\\utils\\util.py 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 def path_validation ( file_path : str , check_for_file : bool = False , check_for_file_type : Union [ str , None ] = None , ) -> None : \"\"\"Utility function for validating the path. Args: file_path (str): Path to be validated check_for_file (bool): Checks for existence of file check_for_file_type (Union[str, None]): Check if file is of this type Raises: PathDoesNotExist: Raises if path does not exist NotAFileError: Raises if file is not present InvalidFileTypePassed: Raises if invalid file type is passed \"\"\" file_path = Path ( file_path ) if not file_path . exists (): logger . error ( f \" { file_path } does not exist!\" ) raise PathDoesNotExist ( file_path ) if check_for_file and file_path . is_dir (): logger . error ( f \"Expected file but got folder : { file_path } \" ) raise NotAFileError ( file_path ) if check_for_file_type and file_path . suffix != check_for_file_type : raise InvalidFileTypePassed ( file_path , check_for_file_type ) logger . debug ( f \" { file_path } validated successfully!\" )","title":"path_validation()"},{"location":"utils_util/#erad.utils.util.read_file","text":"Utility function to read file into a python dict. Supports json, yaml and geojson. Parameters: Name Type Description Default file_path str Path to a file to be read. required Raises: Type Description FeatureNotImplementedError Raises if invalid file is passed. Returns: Name Type Description dict dict Python dict containing content of file. Source code in erad\\utils\\util.py 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 @timeit def read_file ( file_path : str ) -> dict : \"\"\"Utility function to read file into a python dict. Supports json, yaml and geojson. Args: file_path (str): Path to a file to be read. Raises: FeatureNotImplementedError: Raises if invalid file is passed. Returns: dict: Python dict containing content of file. \"\"\" file_path = Path ( file_path ) logger . debug ( f \"Attempting to read { file_path } \" ) path_validation ( file_path , check_for_file = True ) # Handle JSON file read if file_path . suffix == \".json\" : with open ( file_path , \"r\" ) as f : content = json . load ( f ) # Handle YAML file read elif file_path . suffix == \".yaml\" : with open ( file_path , \"r\" ) as f : content = yaml . safe_load ( f ) # Handle geojson file read elif file_path . suffix == \".geojson\" : with open ( file_path , \"r\" ) as f : content = geojson . load ( f ) else : logger . error ( f \"Could not read the { file_path } , this feature is not yet implemented\" ) raise FeatureNotImplementedError ( f \"File of type { file_path . suffix } \\ is not yet implemented for reading purpose\" ) logger . debug ( f \" { file_path } read successfully\" ) return content","title":"read_file()"},{"location":"utils_util/#erad.utils.util.setup_logging","text":"Creates log directory and sets up logging via logging.yaml. Parameters: Name Type Description Default filename str Path to logging.yaml file None If not providex expects log file in the root of repo. Source code in erad\\utils\\util.py 44 45 46 47 48 49 50 51 52 53 54 55 56 def setup_logging ( filename : Union [ str , None ] = None ) -> None : \"\"\"Creates log directory and sets up logging via logging.yaml. Args: filename (str): Path to logging.yaml file If not providex expects log file in the root of repo. \"\"\" if filename is None : filename = Path ( __file__ ) . parents [ 2 ] / \"logging.yaml\" logging . config . dictConfig ( read_file ( filename ))","title":"setup_logging()"},{"location":"utils_util/#erad.utils.util.timeit","text":"Decorator for timing execution of a function. Source code in erad\\utils\\util.py 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 def timeit ( func ): \"\"\"Decorator for timing execution of a function.\"\"\" def wrapper ( * args , ** kwargs ): time_start = time . perf_counter () logger . debug ( f \"Timing for { func } started\" ) ret_val = func ( * args , ** kwargs ) time_elapsed = time . perf_counter () - time_start # memory_mb =resource.getrusage(resource.RUSAGE_SELF).ru_maxrss/1024.0/1024.0 logger . debug ( f \"Time took to execute the function { func } \\ with args { args } , kwargs { kwargs } is { time_elapsed } seconds\" ) return ret_val return wrapper","title":"timeit()"},{"location":"utils_util/#erad.utils.util.write_file","text":"Utility function to write to a file.. Supports json, yaml and geojson. Parameters: Name Type Description Default content dict Python dict content required file_path str Path to a file to be read required kwargs dict Keyword arguments passed to relevant writer. required Raises: Type Description FeatureNotImplementedError Raises if invalid file type is passed. Source code in erad\\utils\\util.py 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 def write_file ( content : dict , file_path : str , ** kwargs ) -> None : \"\"\"Utility function to write to a file.. Supports json, yaml and geojson. Args: content (dict): Python dict content file_path (str): Path to a file to be read kwargs (dict): Keyword arguments passed to relevant writer. Raises: FeatureNotImplementedError: Raises if invalid file type is passed. \"\"\" file_path = Path ( file_path ) path_validation ( file_path . parent ) # Handle JSON file write if file_path . suffix == \".json\" : with open ( file_path , \"w\" ) as f : json . dump ( content , f , ** kwargs ) # Handle YAML file write elif file_path . suffix == \".yaml\" : with open ( file_path , \"w\" ) as f : yaml . safe_dump ( content , f , ** kwargs ) # Handle geojson file write elif file_path . suffix == \".geojson\" : with open ( file_path , \"w\" ) as f : geojson . dump ( content , f , ** kwargs ) else : raise FeatureNotImplementedError ( f \"File of type { file_path . suffix } \\ is not yet implemented for writing purpose\" )","title":"write_file()"},{"location":"visualization_plot_graph/","text":"Module for handling graph plots. AbstractGraphPlot Bases: abc . ABC Abstract interface for developing subclass to plot network graph. Source code in erad\\visualization\\plot_graph.py 19 20 21 22 23 24 25 26 27 28 class AbstractGraphPlot ( abc . ABC ): \"\"\"Abstract interface for developing subclass to plot network graph.\"\"\" @abc . abstractmethod def add_network_data ( self , * args , ** kwargs ): \"\"\"Abstract method for adding network data.\"\"\" @abc . abstractmethod def prepare_plot ( self , * args , ** kwargs ): \"\"\"Abstract method for preparing and showing teh plot\"\"\" add_network_data ( * args , ** kwargs ) abstractmethod Abstract method for adding network data. Source code in erad\\visualization\\plot_graph.py 22 23 24 @abc . abstractmethod def add_network_data ( self , * args , ** kwargs ): \"\"\"Abstract method for adding network data.\"\"\" prepare_plot ( * args , ** kwargs ) abstractmethod Abstract method for preparing and showing teh plot Source code in erad\\visualization\\plot_graph.py 26 27 28 @abc . abstractmethod def prepare_plot ( self , * args , ** kwargs ): \"\"\"Abstract method for preparing and showing teh plot\"\"\" PloltyGraph Bases: AbstractGraphPlot Class for managing graph plot using Plotly. Attributes: Name Type Description access_token str MapBox API token style str MapBox style zoom_level int Zoom level for the plot data List Stores the data to be fed to plotly for plotting scatter_data Dict Stores longitudes and latitudes of nodes from network fig go . Figure Plotly graph objects figure instance Source code in erad\\visualization\\plot_graph.py 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 class PloltyGraph ( AbstractGraphPlot ): \"\"\"Class for managing graph plot using Plotly. Attributes: access_token (str): MapBox API token style (str): MapBox style zoom_level (int): Zoom level for the plot data (List): Stores the data to be fed to plotly for plotting scatter_data (Dict): Stores longitudes and latitudes of nodes from network fig (go.Figure): Plotly graph objects figure instance \"\"\" def __init__ ( self , access_token : str = None , style : str = \"carto-darkmatter\" , zoom_level : int = 13 , ) -> None : \"\"\"Constructor for `PlotlyGraph` Subclass. Args: access_token (str): MapBox API token style (str): MapBox style zoom_level (int): Zoom level for the plot \"\"\" if access_token : self . access_token = access_token else : self . access_token = os . getenv ( \"MAPBOX_API_KEY\" ) self . style = style self . zoom_level = zoom_level self . data = [] def _get_map_centre ( self , longitudes : List [ float ], latitudes : List [ float ]): \"\"\"Returns map center.\"\"\" return { \"lon\" : sum ( longitudes ) / len ( longitudes ), \"lat\" : sum ( latitudes ) / len ( latitudes ), } def add_network_data ( self , network : nx . Graph , latitude_property : str = \"lat\" , longitude_property : str = \"long\" , node_color : str = \"blue\" , line_color : str = \"red\" , ) -> None : \"\"\"Method to add network data to plot data. Args: network (nx.Graph): Networkx graph instance latitude_property (str): Property name to be used as latitude longitude_property (str): Property name to be used as longitude node_color (str): Color name to be used to plot nodes line_color (str): Color name to be used to plot line segments \"\"\" # Add nodes self . scatter_data = { \"latitudes\" : [], \"longitudes\" : []} for node in network . nodes . data (): # Storing the lat lons in scatter data # container self . scatter_data [ \"latitudes\" ] . append ( node [ 1 ][ latitude_property ]) self . scatter_data [ \"longitudes\" ] . append ( node [ 1 ][ longitude_property ]) # Stroing the edge data in container line_data = { \"latitudes\" : [], \"longitudes\" : []} node_data = { node [ 0 ]: node [ 1 ] for node in network . nodes . data ()} for edge in network . edges (): line_data [ \"latitudes\" ] . extend ( [ node_data [ edge [ 0 ]][ latitude_property ], node_data [ edge [ 1 ]][ latitude_property ], None , ] ) line_data [ \"longitudes\" ] . extend ( [ node_data [ edge [ 0 ]][ longitude_property ], node_data [ edge [ 1 ]][ longitude_property ], None , ] ) # Adding plots to plotly graph object self . data . append ( go . Scattermapbox ( mode = \"markers\" , lon = self . scatter_data [ \"longitudes\" ], lat = self . scatter_data [ \"latitudes\" ], marker = { \"size\" : 5 , \"color\" : node_color }, ) ) self . data . append ( go . Scattermapbox ( mode = \"markers+lines\" , lon = line_data [ \"longitudes\" ], lat = line_data [ \"latitudes\" ], marker = { \"size\" : 0 }, line = { \"color\" : line_color }, ) ) def add_scatter_points ( self , latitudes : List [ float ], longitudes : List [ float ], color : str = \"yellow\" , size : int = 5 , ) -> None : \"\"\"Method for scatter points to plot data. Args: latitudes (List[float]): List of latitude points longitudes (List[float]): List of longitude points color (str): Color to be used for scatter points size (int): Size of scatter points \"\"\" self . data . append ( go . Scattermapbox ( mode = \"markers\" , lon = longitudes , lat = latitudes , marker = { \"size\" : size , \"color\" : color }, ) ) def add_polygon ( self , latitudes : List [ float ], longitudes : List [ float ], fill : str = \"toself\" , ) -> None : \"\"\"Method for adding polygon to the plot. Args: latitudes (List[float]): List of latitude points longitudes (List[float]): List of longitude points fill (str): Accepted fill value by plotly \"\"\" self . data . append ( go . Scattermapbox ( lon = longitudes , lat = latitudes , fill = fill , mode = \"lines\" ) ) def prepare_plot ( self , show : bool = True ): \"\"\"Method to prepare and show the plot. Args: show (bool): True if want to see the plot. \"\"\" self . fig = go . Figure ( data = self . data ) self . fig . update_layout ( margin = { \"r\" : 0 , \"t\" : 0 , \"l\" : 0 , \"b\" : 0 }) self . fig . update_mapboxes ( { \"accesstoken\" : self . access_token , \"style\" : self . style , \"center\" : self . _get_map_centre ( self . scatter_data [ \"longitudes\" ], self . scatter_data [ \"latitudes\" ], ), \"zoom\" : self . zoom_level , } ) if show : self . fig . show () def html_export ( self , html_file_path : str ): \"\"\"Method for exporting plot as HTML file.\"\"\" path_validation ( html_file_path ) self . fig . write_html ( html_file_path ) __init__ ( access_token = None , style = 'carto-darkmatter' , zoom_level = 13 ) Constructor for PlotlyGraph Subclass. Parameters: Name Type Description Default access_token str MapBox API token None style str MapBox style 'carto-darkmatter' zoom_level int Zoom level for the plot 13 Source code in erad\\visualization\\plot_graph.py 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 def __init__ ( self , access_token : str = None , style : str = \"carto-darkmatter\" , zoom_level : int = 13 , ) -> None : \"\"\"Constructor for `PlotlyGraph` Subclass. Args: access_token (str): MapBox API token style (str): MapBox style zoom_level (int): Zoom level for the plot \"\"\" if access_token : self . access_token = access_token else : self . access_token = os . getenv ( \"MAPBOX_API_KEY\" ) self . style = style self . zoom_level = zoom_level self . data = [] add_network_data ( network , latitude_property = 'lat' , longitude_property = 'long' , node_color = 'blue' , line_color = 'red' ) Method to add network data to plot data. Parameters: Name Type Description Default network nx . Graph Networkx graph instance required latitude_property str Property name to be used as latitude 'lat' longitude_property str Property name to be used as longitude 'long' node_color str Color name to be used to plot nodes 'blue' line_color str Color name to be used to plot line segments 'red' Source code in erad\\visualization\\plot_graph.py 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 def add_network_data ( self , network : nx . Graph , latitude_property : str = \"lat\" , longitude_property : str = \"long\" , node_color : str = \"blue\" , line_color : str = \"red\" , ) -> None : \"\"\"Method to add network data to plot data. Args: network (nx.Graph): Networkx graph instance latitude_property (str): Property name to be used as latitude longitude_property (str): Property name to be used as longitude node_color (str): Color name to be used to plot nodes line_color (str): Color name to be used to plot line segments \"\"\" # Add nodes self . scatter_data = { \"latitudes\" : [], \"longitudes\" : []} for node in network . nodes . data (): # Storing the lat lons in scatter data # container self . scatter_data [ \"latitudes\" ] . append ( node [ 1 ][ latitude_property ]) self . scatter_data [ \"longitudes\" ] . append ( node [ 1 ][ longitude_property ]) # Stroing the edge data in container line_data = { \"latitudes\" : [], \"longitudes\" : []} node_data = { node [ 0 ]: node [ 1 ] for node in network . nodes . data ()} for edge in network . edges (): line_data [ \"latitudes\" ] . extend ( [ node_data [ edge [ 0 ]][ latitude_property ], node_data [ edge [ 1 ]][ latitude_property ], None , ] ) line_data [ \"longitudes\" ] . extend ( [ node_data [ edge [ 0 ]][ longitude_property ], node_data [ edge [ 1 ]][ longitude_property ], None , ] ) # Adding plots to plotly graph object self . data . append ( go . Scattermapbox ( mode = \"markers\" , lon = self . scatter_data [ \"longitudes\" ], lat = self . scatter_data [ \"latitudes\" ], marker = { \"size\" : 5 , \"color\" : node_color }, ) ) self . data . append ( go . Scattermapbox ( mode = \"markers+lines\" , lon = line_data [ \"longitudes\" ], lat = line_data [ \"latitudes\" ], marker = { \"size\" : 0 }, line = { \"color\" : line_color }, ) ) add_polygon ( latitudes , longitudes , fill = 'toself' ) Method for adding polygon to the plot. Parameters: Name Type Description Default latitudes List [ float ] List of latitude points required longitudes List [ float ] List of longitude points required fill str Accepted fill value by plotly 'toself' Source code in erad\\visualization\\plot_graph.py 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 def add_polygon ( self , latitudes : List [ float ], longitudes : List [ float ], fill : str = \"toself\" , ) -> None : \"\"\"Method for adding polygon to the plot. Args: latitudes (List[float]): List of latitude points longitudes (List[float]): List of longitude points fill (str): Accepted fill value by plotly \"\"\" self . data . append ( go . Scattermapbox ( lon = longitudes , lat = latitudes , fill = fill , mode = \"lines\" ) ) add_scatter_points ( latitudes , longitudes , color = 'yellow' , size = 5 ) Method for scatter points to plot data. Parameters: Name Type Description Default latitudes List [ float ] List of latitude points required longitudes List [ float ] List of longitude points required color str Color to be used for scatter points 'yellow' size int Size of scatter points 5 Source code in erad\\visualization\\plot_graph.py 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 def add_scatter_points ( self , latitudes : List [ float ], longitudes : List [ float ], color : str = \"yellow\" , size : int = 5 , ) -> None : \"\"\"Method for scatter points to plot data. Args: latitudes (List[float]): List of latitude points longitudes (List[float]): List of longitude points color (str): Color to be used for scatter points size (int): Size of scatter points \"\"\" self . data . append ( go . Scattermapbox ( mode = \"markers\" , lon = longitudes , lat = latitudes , marker = { \"size\" : size , \"color\" : color }, ) ) html_export ( html_file_path ) Method for exporting plot as HTML file. Source code in erad\\visualization\\plot_graph.py 214 215 216 217 def html_export ( self , html_file_path : str ): \"\"\"Method for exporting plot as HTML file.\"\"\" path_validation ( html_file_path ) self . fig . write_html ( html_file_path ) prepare_plot ( show = True ) Method to prepare and show the plot. Parameters: Name Type Description Default show bool True if want to see the plot. True Source code in erad\\visualization\\plot_graph.py 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 def prepare_plot ( self , show : bool = True ): \"\"\"Method to prepare and show the plot. Args: show (bool): True if want to see the plot. \"\"\" self . fig = go . Figure ( data = self . data ) self . fig . update_layout ( margin = { \"r\" : 0 , \"t\" : 0 , \"l\" : 0 , \"b\" : 0 }) self . fig . update_mapboxes ( { \"accesstoken\" : self . access_token , \"style\" : self . style , \"center\" : self . _get_map_centre ( self . scatter_data [ \"longitudes\" ], self . scatter_data [ \"latitudes\" ], ), \"zoom\" : self . zoom_level , } ) if show : self . fig . show ()","title":"visualization.plot_graph"},{"location":"visualization_plot_graph/#erad.visualization.plot_graph.AbstractGraphPlot","text":"Bases: abc . ABC Abstract interface for developing subclass to plot network graph. Source code in erad\\visualization\\plot_graph.py 19 20 21 22 23 24 25 26 27 28 class AbstractGraphPlot ( abc . ABC ): \"\"\"Abstract interface for developing subclass to plot network graph.\"\"\" @abc . abstractmethod def add_network_data ( self , * args , ** kwargs ): \"\"\"Abstract method for adding network data.\"\"\" @abc . abstractmethod def prepare_plot ( self , * args , ** kwargs ): \"\"\"Abstract method for preparing and showing teh plot\"\"\"","title":"AbstractGraphPlot"},{"location":"visualization_plot_graph/#erad.visualization.plot_graph.AbstractGraphPlot.add_network_data","text":"Abstract method for adding network data. Source code in erad\\visualization\\plot_graph.py 22 23 24 @abc . abstractmethod def add_network_data ( self , * args , ** kwargs ): \"\"\"Abstract method for adding network data.\"\"\"","title":"add_network_data()"},{"location":"visualization_plot_graph/#erad.visualization.plot_graph.AbstractGraphPlot.prepare_plot","text":"Abstract method for preparing and showing teh plot Source code in erad\\visualization\\plot_graph.py 26 27 28 @abc . abstractmethod def prepare_plot ( self , * args , ** kwargs ): \"\"\"Abstract method for preparing and showing teh plot\"\"\"","title":"prepare_plot()"},{"location":"visualization_plot_graph/#erad.visualization.plot_graph.PloltyGraph","text":"Bases: AbstractGraphPlot Class for managing graph plot using Plotly. Attributes: Name Type Description access_token str MapBox API token style str MapBox style zoom_level int Zoom level for the plot data List Stores the data to be fed to plotly for plotting scatter_data Dict Stores longitudes and latitudes of nodes from network fig go . Figure Plotly graph objects figure instance Source code in erad\\visualization\\plot_graph.py 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 class PloltyGraph ( AbstractGraphPlot ): \"\"\"Class for managing graph plot using Plotly. Attributes: access_token (str): MapBox API token style (str): MapBox style zoom_level (int): Zoom level for the plot data (List): Stores the data to be fed to plotly for plotting scatter_data (Dict): Stores longitudes and latitudes of nodes from network fig (go.Figure): Plotly graph objects figure instance \"\"\" def __init__ ( self , access_token : str = None , style : str = \"carto-darkmatter\" , zoom_level : int = 13 , ) -> None : \"\"\"Constructor for `PlotlyGraph` Subclass. Args: access_token (str): MapBox API token style (str): MapBox style zoom_level (int): Zoom level for the plot \"\"\" if access_token : self . access_token = access_token else : self . access_token = os . getenv ( \"MAPBOX_API_KEY\" ) self . style = style self . zoom_level = zoom_level self . data = [] def _get_map_centre ( self , longitudes : List [ float ], latitudes : List [ float ]): \"\"\"Returns map center.\"\"\" return { \"lon\" : sum ( longitudes ) / len ( longitudes ), \"lat\" : sum ( latitudes ) / len ( latitudes ), } def add_network_data ( self , network : nx . Graph , latitude_property : str = \"lat\" , longitude_property : str = \"long\" , node_color : str = \"blue\" , line_color : str = \"red\" , ) -> None : \"\"\"Method to add network data to plot data. Args: network (nx.Graph): Networkx graph instance latitude_property (str): Property name to be used as latitude longitude_property (str): Property name to be used as longitude node_color (str): Color name to be used to plot nodes line_color (str): Color name to be used to plot line segments \"\"\" # Add nodes self . scatter_data = { \"latitudes\" : [], \"longitudes\" : []} for node in network . nodes . data (): # Storing the lat lons in scatter data # container self . scatter_data [ \"latitudes\" ] . append ( node [ 1 ][ latitude_property ]) self . scatter_data [ \"longitudes\" ] . append ( node [ 1 ][ longitude_property ]) # Stroing the edge data in container line_data = { \"latitudes\" : [], \"longitudes\" : []} node_data = { node [ 0 ]: node [ 1 ] for node in network . nodes . data ()} for edge in network . edges (): line_data [ \"latitudes\" ] . extend ( [ node_data [ edge [ 0 ]][ latitude_property ], node_data [ edge [ 1 ]][ latitude_property ], None , ] ) line_data [ \"longitudes\" ] . extend ( [ node_data [ edge [ 0 ]][ longitude_property ], node_data [ edge [ 1 ]][ longitude_property ], None , ] ) # Adding plots to plotly graph object self . data . append ( go . Scattermapbox ( mode = \"markers\" , lon = self . scatter_data [ \"longitudes\" ], lat = self . scatter_data [ \"latitudes\" ], marker = { \"size\" : 5 , \"color\" : node_color }, ) ) self . data . append ( go . Scattermapbox ( mode = \"markers+lines\" , lon = line_data [ \"longitudes\" ], lat = line_data [ \"latitudes\" ], marker = { \"size\" : 0 }, line = { \"color\" : line_color }, ) ) def add_scatter_points ( self , latitudes : List [ float ], longitudes : List [ float ], color : str = \"yellow\" , size : int = 5 , ) -> None : \"\"\"Method for scatter points to plot data. Args: latitudes (List[float]): List of latitude points longitudes (List[float]): List of longitude points color (str): Color to be used for scatter points size (int): Size of scatter points \"\"\" self . data . append ( go . Scattermapbox ( mode = \"markers\" , lon = longitudes , lat = latitudes , marker = { \"size\" : size , \"color\" : color }, ) ) def add_polygon ( self , latitudes : List [ float ], longitudes : List [ float ], fill : str = \"toself\" , ) -> None : \"\"\"Method for adding polygon to the plot. Args: latitudes (List[float]): List of latitude points longitudes (List[float]): List of longitude points fill (str): Accepted fill value by plotly \"\"\" self . data . append ( go . Scattermapbox ( lon = longitudes , lat = latitudes , fill = fill , mode = \"lines\" ) ) def prepare_plot ( self , show : bool = True ): \"\"\"Method to prepare and show the plot. Args: show (bool): True if want to see the plot. \"\"\" self . fig = go . Figure ( data = self . data ) self . fig . update_layout ( margin = { \"r\" : 0 , \"t\" : 0 , \"l\" : 0 , \"b\" : 0 }) self . fig . update_mapboxes ( { \"accesstoken\" : self . access_token , \"style\" : self . style , \"center\" : self . _get_map_centre ( self . scatter_data [ \"longitudes\" ], self . scatter_data [ \"latitudes\" ], ), \"zoom\" : self . zoom_level , } ) if show : self . fig . show () def html_export ( self , html_file_path : str ): \"\"\"Method for exporting plot as HTML file.\"\"\" path_validation ( html_file_path ) self . fig . write_html ( html_file_path )","title":"PloltyGraph"},{"location":"visualization_plot_graph/#erad.visualization.plot_graph.PloltyGraph.__init__","text":"Constructor for PlotlyGraph Subclass. Parameters: Name Type Description Default access_token str MapBox API token None style str MapBox style 'carto-darkmatter' zoom_level int Zoom level for the plot 13 Source code in erad\\visualization\\plot_graph.py 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 def __init__ ( self , access_token : str = None , style : str = \"carto-darkmatter\" , zoom_level : int = 13 , ) -> None : \"\"\"Constructor for `PlotlyGraph` Subclass. Args: access_token (str): MapBox API token style (str): MapBox style zoom_level (int): Zoom level for the plot \"\"\" if access_token : self . access_token = access_token else : self . access_token = os . getenv ( \"MAPBOX_API_KEY\" ) self . style = style self . zoom_level = zoom_level self . data = []","title":"__init__()"},{"location":"visualization_plot_graph/#erad.visualization.plot_graph.PloltyGraph.add_network_data","text":"Method to add network data to plot data. Parameters: Name Type Description Default network nx . Graph Networkx graph instance required latitude_property str Property name to be used as latitude 'lat' longitude_property str Property name to be used as longitude 'long' node_color str Color name to be used to plot nodes 'blue' line_color str Color name to be used to plot line segments 'red' Source code in erad\\visualization\\plot_graph.py 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 def add_network_data ( self , network : nx . Graph , latitude_property : str = \"lat\" , longitude_property : str = \"long\" , node_color : str = \"blue\" , line_color : str = \"red\" , ) -> None : \"\"\"Method to add network data to plot data. Args: network (nx.Graph): Networkx graph instance latitude_property (str): Property name to be used as latitude longitude_property (str): Property name to be used as longitude node_color (str): Color name to be used to plot nodes line_color (str): Color name to be used to plot line segments \"\"\" # Add nodes self . scatter_data = { \"latitudes\" : [], \"longitudes\" : []} for node in network . nodes . data (): # Storing the lat lons in scatter data # container self . scatter_data [ \"latitudes\" ] . append ( node [ 1 ][ latitude_property ]) self . scatter_data [ \"longitudes\" ] . append ( node [ 1 ][ longitude_property ]) # Stroing the edge data in container line_data = { \"latitudes\" : [], \"longitudes\" : []} node_data = { node [ 0 ]: node [ 1 ] for node in network . nodes . data ()} for edge in network . edges (): line_data [ \"latitudes\" ] . extend ( [ node_data [ edge [ 0 ]][ latitude_property ], node_data [ edge [ 1 ]][ latitude_property ], None , ] ) line_data [ \"longitudes\" ] . extend ( [ node_data [ edge [ 0 ]][ longitude_property ], node_data [ edge [ 1 ]][ longitude_property ], None , ] ) # Adding plots to plotly graph object self . data . append ( go . Scattermapbox ( mode = \"markers\" , lon = self . scatter_data [ \"longitudes\" ], lat = self . scatter_data [ \"latitudes\" ], marker = { \"size\" : 5 , \"color\" : node_color }, ) ) self . data . append ( go . Scattermapbox ( mode = \"markers+lines\" , lon = line_data [ \"longitudes\" ], lat = line_data [ \"latitudes\" ], marker = { \"size\" : 0 }, line = { \"color\" : line_color }, ) )","title":"add_network_data()"},{"location":"visualization_plot_graph/#erad.visualization.plot_graph.PloltyGraph.add_polygon","text":"Method for adding polygon to the plot. Parameters: Name Type Description Default latitudes List [ float ] List of latitude points required longitudes List [ float ] List of longitude points required fill str Accepted fill value by plotly 'toself' Source code in erad\\visualization\\plot_graph.py 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 def add_polygon ( self , latitudes : List [ float ], longitudes : List [ float ], fill : str = \"toself\" , ) -> None : \"\"\"Method for adding polygon to the plot. Args: latitudes (List[float]): List of latitude points longitudes (List[float]): List of longitude points fill (str): Accepted fill value by plotly \"\"\" self . data . append ( go . Scattermapbox ( lon = longitudes , lat = latitudes , fill = fill , mode = \"lines\" ) )","title":"add_polygon()"},{"location":"visualization_plot_graph/#erad.visualization.plot_graph.PloltyGraph.add_scatter_points","text":"Method for scatter points to plot data. Parameters: Name Type Description Default latitudes List [ float ] List of latitude points required longitudes List [ float ] List of longitude points required color str Color to be used for scatter points 'yellow' size int Size of scatter points 5 Source code in erad\\visualization\\plot_graph.py 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 def add_scatter_points ( self , latitudes : List [ float ], longitudes : List [ float ], color : str = \"yellow\" , size : int = 5 , ) -> None : \"\"\"Method for scatter points to plot data. Args: latitudes (List[float]): List of latitude points longitudes (List[float]): List of longitude points color (str): Color to be used for scatter points size (int): Size of scatter points \"\"\" self . data . append ( go . Scattermapbox ( mode = \"markers\" , lon = longitudes , lat = latitudes , marker = { \"size\" : size , \"color\" : color }, ) )","title":"add_scatter_points()"},{"location":"visualization_plot_graph/#erad.visualization.plot_graph.PloltyGraph.html_export","text":"Method for exporting plot as HTML file. Source code in erad\\visualization\\plot_graph.py 214 215 216 217 def html_export ( self , html_file_path : str ): \"\"\"Method for exporting plot as HTML file.\"\"\" path_validation ( html_file_path ) self . fig . write_html ( html_file_path )","title":"html_export()"},{"location":"visualization_plot_graph/#erad.visualization.plot_graph.PloltyGraph.prepare_plot","text":"Method to prepare and show the plot. Parameters: Name Type Description Default show bool True if want to see the plot. True Source code in erad\\visualization\\plot_graph.py 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 def prepare_plot ( self , show : bool = True ): \"\"\"Method to prepare and show the plot. Args: show (bool): True if want to see the plot. \"\"\" self . fig = go . Figure ( data = self . data ) self . fig . update_layout ( margin = { \"r\" : 0 , \"t\" : 0 , \"l\" : 0 , \"b\" : 0 }) self . fig . update_mapboxes ( { \"accesstoken\" : self . access_token , \"style\" : self . style , \"center\" : self . _get_map_centre ( self . scatter_data [ \"longitudes\" ], self . scatter_data [ \"latitudes\" ], ), \"zoom\" : self . zoom_level , } ) if show : self . fig . show ()","title":"prepare_plot()"}]}